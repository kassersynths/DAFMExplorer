{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<div align=\"center\" style=\"background: #ffffff; padding: 40px; margin-bottom: 10px;\">\n",
    "\n",
    "<!-- Kasser Synths Logo -->\n",
    "<img src=\"images/logo-kasser-synths.svg\" alt=\"Kasser Synths Logo\" style=\"width: 400px; max-width: 90%; height: auto; display: block; margin-left: auto; margin-right: auto;\" />\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"center\" style=\"background: linear-gradient(135deg, #000000 0%, #1a1a1a 100%); padding: 20px; border: 2px solid #00d4ff; margin-bottom: 30px;\">\n",
    "\n",
    "<div style=\"font-size: 14px; color: #00d4ff; letter-spacing: 3px;\">\n",
    "FM SYNTHESIS ‚Ä¢ DATA SCIENCE ‚Ä¢ RETRO GAMING\n",
    "</div>\n",
    "\n",
    "</div>\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "# The Sound of a Generation: Data Science on 93,000 FM Presets\n",
    "\n",
    "## Exploring the Sonic DNA of the Sega Genesis/Mega Drive Era\n",
    "\n",
    "</div>\n",
    "\n",
    "The 80s and 90s were decades of innovation in electronic music and video gaming, largely thanks to the iconic **YM2612 chip** from Yamaha‚Äîthe sonic heart of the Sega Genesis/Mega Drive. This notebook explores a treasure trove of **93,000+ presets** extracted from VGM files, uncovering patterns, relationships, and the creative signatures of legendary composers.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Sega Genesis Console](images/Sega-Genesis-Mod1-Bare.jpg)\n",
    "\n",
    "*The Sega Genesis/Mega Drive console with accessories. The YM2612 chip inside this console defined the sound of a generation.*  \n",
    "*Image: [Evan-Amos / Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Sega-Genesis-Model-2-Monster.jpg) - Public Domain*\n",
    "\n",
    "</div>\n",
    "\n",
    "### üìú The Data: 93,000+ Presets from a Generation\n",
    "\n",
    "| Source | Description |\n",
    "|--------|-------------|\n",
    "| **VGM Files** | Recordings of exact chip commands from Project2612 & VGMrips |\n",
    "| **Extracted by** | DrWashington (complete collection up to 2010) |\n",
    "| **Found on** | KVRist forum - a treasure trove of creative work |\n",
    "\n",
    "**What's Hidden in the Data?**\n",
    "- üéµ Composer signatures and techniques\n",
    "- üåç Regional differences (Japan vs USA vs Europe)\n",
    "- üìà Evolution of sound design over time\n",
    "- üîó Relationships between games and genres\n",
    "\n",
    "**The Questions We'll Answer:**\n",
    "- Can we identify a composer just from their preset parameters?\n",
    "- Which parameter combinations defined the \"Genesis sound\"?\n",
    "- Do games cluster by sonic similarity?\n",
    "\n",
    "**Let's dive in!** üéµüéÆ\n",
    "\n",
    "### üéì Two Perspectives, One Journey\n",
    "\n",
    "| ü§ñ **Data Scientists** | üéπ **Sound Designers** |\n",
    "|------------------------|------------------------|\n",
    "| Dimensionality reduction (PCA, t-SNE) | YM2612 chip architecture |\n",
    "| Clustering with KMeans | Algorithms & Feedback |\n",
    "| Recommendation systems | Composer signatures |\n",
    "| Feature engineering | Game sonic identities |\n",
    "\n",
    "<div style=\"border-left: 4px solid #00d4ff; padding-left: 15px; margin: 20px 0; background-color: #0a0a0a; padding: 10px;\">\n",
    "<strong style=\"color: #00d4ff;\">PROJECT BY KASSER SYNTHS</strong><br>\n",
    "Exploring the legacy of FM synthesis in video game music.\n",
    "</div>\n",
    "\n",
    "### üìä Dataset at a Glance\n",
    "\n",
    "| Metric | Value |\n",
    "|--------|-------|\n",
    "| **Total Presets** | ~93,800 |\n",
    "| **Parameters** | 58 (global + 4 operators) |\n",
    "| **Source** | VGM files (Project2612) |\n",
    "| **Format** | OPM ‚Üí CSV |\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Sega Genesis Controller](images/Sega-Genesis-6But-Cont.jpg)\n",
    "\n",
    "*The iconic 6-button Genesis controller - The interface that connected millions to the YM2612's sounds.*  \n",
    "*Image: [Evan-Amos / Wikimedia Commons](https://commons.wikimedia.org/wiki/File:Sega-Genesis-Mk2-6button.jpg) - Public Domain*\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**Let's dive into the data!** üéµüéÆ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART I: THE FM SYNTHESIS REVOLUTION\n",
    "\n",
    "## 1. Introduction and Context\n",
    "\n",
    "We've already seen the cover with the Kasser Synths logo and the dataset introduction. Now let's explore the history of FM synthesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. History of FM Synthesis\n",
    "\n",
    "### 2.1 John Chowning y Stanford (1960s-1970s)\n",
    "\n",
    "**The Birth of FM Synthesis (1967-1973)**\n",
    "\n",
    "In the late 1960s, **John Chowning**, a composer and researcher at Stanford University's Center for Computer Research in Music and Acoustics (CCRMA), made a revolutionary discovery. While experimenting with digital audio synthesis, he found that **frequency modulation**‚Äîusing one oscillator to modulate the frequency of another‚Äîcould create incredibly rich, complex timbres.\n",
    "\n",
    "**The Breakthrough:**\n",
    "- **1967**: Chowning discovers that FM can create musical timbres\n",
    "- **1971**: First musical composition using FM synthesis\n",
    "- **1973**: Stanford patents the FM synthesis algorithm\n",
    "- **1975**: Yamaha licenses the patent from Stanford\n",
    "\n",
    "**Why This Mattered:**\n",
    "Before FM synthesis, creating complex sounds required multiple oscillators and filters‚Äîexpensive and computationally intensive. FM synthesis could create the same rich timbres using just **two oscillators** (called \"operators\" in FM terminology). This was revolutionary because:\n",
    "- **Computational efficiency**: Less processing power needed\n",
    "- **Rich timbres**: Complex sounds from simple algorithms\n",
    "- **Musical expressiveness**: Natural-sounding instruments\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![John Chowning](images/John-Chowning-Stanford.jpg)\n",
    "\n",
    "*John Chowning at Stanford University - The man who discovered FM synthesis*  \n",
    "*Image: Stanford University / CCRMA*\n",
    "\n",
    "</div>\n",
    "\n",
    "**The Stanford Connection:**\n",
    "Stanford's CCRMA became a hub for digital audio innovation. The research conducted there didn't just lead to FM synthesis‚Äîit influenced the entire field of computer music. Chowning's work showed that **mathematical algorithms could create beautiful, musical sounds**, a concept that would shape video game music for decades.\n",
    "\n",
    "**The Patent:**\n",
    "Stanford's patent on FM synthesis (US Patent 4,018,121) was one of the most valuable patents in the university's history. The licensing revenue helped fund further research and established Stanford as a leader in digital audio technology."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Yamaha DX7 (1983)\n",
    "\n",
    "**1983: The Revolution Begins**\n",
    "\n",
    "The **Yamaha DX7** wasn't just a synthesizer‚Äîit was a cultural phenomenon. Released in 1983, it became the best-selling synthesizer of all time, with over 200,000 units sold. But more importantly, it brought FM synthesis to the masses.\n",
    "\n",
    "**Why the DX7 Was Revolutionary:**\n",
    "- **First affordable FM synthesizer**: Previous FM synths were expensive research instruments\n",
    "- **16-voice polyphony**: Could play 16 notes simultaneously\n",
    "- **32 algorithms**: 32 different ways to connect 6 operators\n",
    "- **Preset-based**: Came with 32 factory presets that became iconic sounds\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Yamaha DX7](images/Yamaha-DX7.jpg)\n",
    "\n",
    "*The Yamaha DX7 - The synthesizer that brought FM synthesis to the world*  \n",
    "*Image: Wikimedia Commons - Public Domain*\n",
    "\n",
    "</div>\n",
    "\n",
    "**The DX7's Impact on Music:**\n",
    "The DX7's presets became the sound of the 1980s:\n",
    "- **\"E.Piano 1\"**: The iconic electric piano sound heard in countless 80s hits\n",
    "- **\"Bass 1\"**: The punchy bass that defined pop music\n",
    "- **\"Brass 1\"**: The bright, synthetic brass sound\n",
    "\n",
    "**From Studio to Arcade:**\n",
    "The DX7's success proved that FM synthesis could create commercially viable sounds. This success caught the attention of video game manufacturers, who saw FM synthesis as a way to create rich, musical soundtracks without the cost and complexity of sampled audio.\n",
    "\n",
    "**The Technical Foundation:**\n",
    "The DX7 used **6 operators** (oscillators) that could be connected in 32 different ways (algorithms). This same concept‚Äîoperators connected in different patterns‚Äîwould become the foundation of the YM2612 chip that powered the Sega Genesis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 FM in the 80s: Yamaha Chips\n",
    "\n",
    "**The Golden Age of FM Chips**\n",
    "\n",
    "The 1980s saw FM synthesis chips appear in every corner of the gaming world. Yamaha created a family of chips optimized for different platforms, each with its own character and capabilities.\n",
    "\n",
    "#### üïπÔ∏è Arcades: The Powerhouses\n",
    "\n",
    "**YM2151 (OPM - \"Operator Music\")**\n",
    "- Used in: Sega System 16 arcade boards (OutRun, After Burner, Golden Axe)\n",
    "- **4 operators, 8 algorithms**\n",
    "- **8 channels** of polyphony\n",
    "- The arcade version of FM synthesis‚Äîpowerful, expressive, and designed for coin-op machines\n",
    "\n",
    "**YM2203 (OPN - \"Operator New\")**\n",
    "- Used in: Various arcade boards and early PC sound cards\n",
    "- **3 operators, 4 algorithms**\n",
    "- Combined FM synthesis with **PSG (Programmable Sound Generator)** for additional sound effects\n",
    "- A versatile chip that bridged arcade and home platforms\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![OutRun Arcade](images/Outrun-Arcade.jpg)\n",
    "\n",
    "*Arcade machines like OutRun used the YM2151 chip for their powerful FM soundtracks*  \n",
    "*Image: Wikimedia Commons*\n",
    "\n",
    "</div>\n",
    "\n",
    "#### üéÆ Consoles: Bringing Arcade Sound Home\n",
    "\n",
    "**YM2612 (OPN2 - \"Operator New 2\")**\n",
    "- Used in: **Sega Genesis / Mega Drive** (1988-1997)\n",
    "- **4 operators, 8 algorithms**\n",
    "- **6 FM channels** + 1 PSG channel\n",
    "- The chip we're analyzing in this notebook!\n",
    "- Brought arcade-quality FM synthesis to home consoles\n",
    "\n",
    "**YM2413 (OPLL - \"Operator Low\")**\n",
    "- Used in: Sega Master System, MSX computers\n",
    "- **2 operators, 15 preset algorithms**\n",
    "- Simplified FM synthesis for budget systems\n",
    "- Still capable of creating rich, musical sounds\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Sega Genesis YM2612](images/YM2612-chip.jpg)\n",
    "\n",
    "*The YM2612 chip - The heart of the Sega Genesis sound*  \n",
    "*Image: Wikimedia Commons - Public Domain*\n",
    "\n",
    "</div>\n",
    "\n",
    "#### üíª PC: FM on Your Desk\n",
    "\n",
    "**YM3812 (OPL2 - \"Operator Low 2\")**\n",
    "- Used in: **AdLib sound card** (1987), Sound Blaster cards\n",
    "- **2 operators, 9 algorithms**\n",
    "- **9 FM channels** + 5 percussion channels\n",
    "- Brought FM synthesis to PC gaming\n",
    "- The sound of early PC games like **Duke Nukem**, **Doom** (with Sound Blaster)\n",
    "\n",
    "**YMF262 (OPL3 - \"Operator Low 3\")**\n",
    "- Used in: Sound Blaster Pro, later PC sound cards\n",
    "- **4 operators, 18 algorithms**\n",
    "- **18 FM channels** + 5 percussion channels\n",
    "- The most powerful FM chip for PCs\n",
    "- Used in games like **Jazz Jackrabbit**, **Commander Keen**\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![AdLib Sound Card](images/Adlib-SoundCard.jpg)\n",
    "\n",
    "*The AdLib sound card with YM3812 chip - FM synthesis for PC gaming*  \n",
    "*Image: Wikimedia Commons*\n",
    "\n",
    "</div>\n",
    "\n",
    "**Why So Many Chips?**\n",
    "Each chip was optimized for its platform:\n",
    "- **Arcade chips**: Maximum power, no cost constraints\n",
    "- **Console chips**: Balance of power and cost\n",
    "- **PC chips**: Compatibility with existing hardware, affordable\n",
    "\n",
    "**The Common Thread:**\n",
    "Despite their differences, all these chips shared the same fundamental concept: **operators connected in algorithms**. This is why understanding FM synthesis helps you understand the sound of an entire era."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 From Video Games to Ringtones\n",
    "\n",
    "**The Unexpected Legacy**\n",
    "\n",
    "In the late 1990s and early 2000s, FM synthesis found a new home: **mobile phones**. Nokia and other manufacturers used simplified FM synthesis chips to create ringtones, bringing FM synthesis to billions of people worldwide.\n",
    "\n",
    "**Why FM for Ringtones?**\n",
    "- **Small file size**: FM presets are just a few bytes of data\n",
    "- **Low processing power**: FM synthesis is computationally efficient\n",
    "- **Musical quality**: FM can create recognizable melodies and harmonies\n",
    "- **No samples needed**: No need to store audio files\n",
    "\n",
    "**The Nokia Era:**\n",
    "- **Nokia 3310** (2000): Iconic phone with FM-based ringtones\n",
    "- **Composer app**: Users could create their own FM ringtones\n",
    "- **\"Nokia Tune\"**: The most recognizable FM melody in history\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![Nokia 3310](images/Nokia-3310.jpg)\n",
    "\n",
    "*Nokia phones used FM synthesis for their ringtones - bringing FM to billions*  \n",
    "*Image: Wikimedia Commons*\n",
    "\n",
    "</div>\n",
    "\n",
    "**The Full Circle:**\n",
    "From Stanford research ‚Üí Yamaha DX7 ‚Üí Arcade machines ‚Üí Home consoles ‚Üí PC sound cards ‚Üí Mobile phones ‚Üí **Your pocket**. FM synthesis went from cutting-edge research to the most widely heard synthesis method in history.\n",
    "\n",
    "**Why This Matters:**\n",
    "The same mathematical principles that Chowning discovered in 1967 are still being used today. The YM2612 chip in the Sega Genesis uses the same fundamental FM synthesis that powers ringtones in your phone. This is the power of **mathematical elegance**‚Äîa discovery that spans decades and platforms.\n",
    "\n",
    "**The Data Science Connection:**\n",
    "In this notebook, we're analyzing 93,000 presets from the YM2612 chip. Each preset is a **creative decision** made by a composer, but they all follow the same mathematical rules discovered by Chowning. By analyzing these presets, we're studying the **creative application** of a mathematical discovery that changed the world of music."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. The YM2612: The Heart of the Genesis\n",
    "\n",
    "**Understanding the Chip We're Analyzing**\n",
    "\n",
    "The **YM2612** (also known as OPN2) is the FM synthesis chip that powered the Sega Genesis / Mega Drive. Understanding its architecture helps us understand the data we're analyzing.\n",
    "\n",
    "**YM2612 Architecture:**\n",
    "- **4 operators** (oscillators): M1, C1, M2, C2\n",
    "- **8 algorithms**: Different ways to connect the 4 operators\n",
    "- **6 FM channels**: Can play 6 different sounds simultaneously\n",
    "- **1 PSG channel**: Additional sound effects (not FM)\n",
    "\n",
    "**The 8 Algorithms:**\n",
    "Each algorithm defines how operators connect:\n",
    "- **Algorithm 0**: M1 ‚Üí M2 ‚Üí C1 ‚Üí C2 (all in series)\n",
    "- **Algorithm 1**: M1 ‚Üí M2 ‚Üí C1, C2 (parallel carriers)\n",
    "- **Algorithm 2**: M1 ‚Üí M2, C1 ‚Üí C2 (two parallel chains)\n",
    "- **Algorithms 3-7**: Various combinations of series and parallel routing\n",
    "\n",
    "**Why Algorithms Matter:**\n",
    "The same 4 operators, connected differently, create completely different sounds. This is why the **CON (Algorithm)** parameter is so important in our analysis‚Äîit defines the fundamental structure of each sound.\n",
    "\n",
    "**The Creative Challenge:**\n",
    "Composers working with the YM2612 had to:\n",
    "- Choose the right algorithm for each sound\n",
    "- Balance 4 operators to create the desired timbre\n",
    "- Work within 6 channels (polyphony limitation)\n",
    "- Create memorable music with limited resources\n",
    "\n",
    "**The Data We're Analyzing:**\n",
    "Each preset in our dataset represents a **creative solution** to these constraints. By analyzing 93,000 presets, we're studying how composers solved the same creative problem in different ways, revealing patterns, preferences, and techniques that defined the sound of a generation.\n",
    "\n",
    "---\n",
    "\n",
    "**Now that we understand the history and technology, let's dive into the data!** üéµ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART II: MACHINE LEARNING - FROM 58 DIMENSIONS TO INSIGHTS\n",
    "\n",
    "## 4. Data Challenge\n",
    "\n",
    "Imagine you're a data scientist faced with a dataset that has **58 different parameters** for each sound. How do you make sense of it? How do you find patterns? How do you visualize relationships?\n",
    "\n",
    "This is the same challenge faced in many real-world data science problems. Whether you're analyzing customer behavior, medical data, or‚Äîin our case‚Äîsound presets, the fundamental challenge is the same: **too many dimensions to understand directly**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Setup and data loading\n",
    "\n",
    "**Before We Begin:**\n",
    "\n",
    "This notebook assumes you've already run `01-Data_Extraction.ipynb` to generate the cleaned dataset. If you haven't, please run that notebook first!\n",
    "\n",
    "**What We'll Load:**\n",
    "- `artifacts/presets_final.csv`: The processed final dataset (duplicates removed per game, data aggregated, etc...)\n",
    "\n",
    "### 5.1 Setup and Imports\n",
    "\n",
    "**Libraries We'll Use:**\n",
    "- **Pandas/NumPy**: Data manipulation and numerical operations\n",
    "- **Scikit-learn**: Machine learning algorithms (PCA, KMeans, NearestNeighbors)\n",
    "- **Plotly**: Interactive visualizations\n",
    "- **Matplotlib/Seaborn**: Static visualizations\n",
    "\n",
    "**Note**: All web scraping code is in `01-Data_Extraction.ipynb`. This notebook focuses on analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# üåê GOOGLE COLAB SETUP\n",
    "# ============================================================\n",
    "# This cell automatically sets up the environment for Google Colab.\n",
    "# If running locally, it does nothing.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Check if running in Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üåê Running in Google Colab - Setting up environment...\")\n",
    "    \n",
    "    # Clone the repository if not already cloned\n",
    "    REPO_URL = \"https://github.com/kassersynths/DAFMExplorer.git\"\n",
    "    REPO_DIR = \"/content/DAFMExplorer\"\n",
    "    \n",
    "    if not os.path.exists(REPO_DIR):\n",
    "        print(f\"   üì• Cloning repository from {REPO_URL}...\")\n",
    "        !git clone {REPO_URL} {REPO_DIR}\n",
    "    else:\n",
    "        print(f\"   ‚úÖ Repository already exists at {REPO_DIR}\")\n",
    "        # Pull latest changes\n",
    "        !cd {REPO_DIR} && git pull\n",
    "    \n",
    "    # Change to the repository directory\n",
    "    os.chdir(REPO_DIR)\n",
    "    print(f\"   üìÇ Working directory: {os.getcwd()}\")\n",
    "    \n",
    "    # Install additional dependencies that might not be in Colab\n",
    "    print(\"   üì¶ Installing additional dependencies...\")\n",
    "    !pip install -q kneed umap-learn\n",
    "    \n",
    "    print(\"   ‚úÖ Colab setup complete!\")\n",
    "else:\n",
    "    print(\"üíª Running locally - no setup needed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Core data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "from typing import Optional, Dict, List, Tuple\n",
    "\n",
    "# Machine learning & statistics\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from kneed import KneeLocator  # For automatic elbow detection\n",
    "import joblib\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "# Check for UMAP (optional, faster alternative to t-SNE)\n",
    "try:\n",
    "    import umap\n",
    "    HAS_UMAP = True\n",
    "except ImportError:\n",
    "    HAS_UMAP = False\n",
    "\n",
    "# Configuration\n",
    "pd.set_option('display.max_columns', 200)\n",
    "pd.set_option('display.width', 160)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Set style - Kasser Synths theme\n",
    "plt.style.use('dark_background')\n",
    "# Custom Kasser Synths color palette\n",
    "KASSER_COLORS = {\n",
    "    'primary': '#00d4ff',      # Cyan\n",
    "    'secondary': '#ff0080',    # Magenta\n",
    "    'tertiary': '#00ff88',    # Green\n",
    "    'background': '#000000',   # Black\n",
    "    'text': '#ffffff',         # White\n",
    "    'accent': '#cc00ff'        # Purple\n",
    "}\n",
    "\n",
    "# Set matplotlib rcParams for Kasser Synths theme\n",
    "plt.rcParams.update({\n",
    "    'figure.facecolor': '#000000',\n",
    "    'axes.facecolor': '#000000',\n",
    "    'axes.edgecolor': '#00d4ff',\n",
    "    'axes.labelcolor': '#ffffff',\n",
    "    'text.color': '#ffffff',\n",
    "    'xtick.color': '#ffffff',\n",
    "    'ytick.color': '#ffffff',\n",
    "    'grid.color': '#333333',\n",
    "    'figure.edgecolor': '#000000',\n",
    "    'savefig.facecolor': '#000000',\n",
    "    'savefig.edgecolor': '#000000',\n",
    "})\n",
    "\n",
    "# Custom seaborn palette based on Kasser Synths colors\n",
    "sns.set_palette([KASSER_COLORS['primary'], KASSER_COLORS['secondary'], \n",
    "                 KASSER_COLORS['tertiary'], KASSER_COLORS['accent']])\n",
    "\n",
    "# Create artifacts directory for caching\n",
    "ARTIFACTS_DIR = Path('artifacts')\n",
    "ARTIFACTS_DIR.mkdir(exist_ok=True)\n",
    "\n",
    "print('‚úÖ All libraries loaded successfully!')\n",
    "print(f'üé® Kasser Synths theme applied: {KASSER_COLORS[\"primary\"]}, {KASSER_COLORS[\"secondary\"]}, {KASSER_COLORS[\"tertiary\"]}')\n",
    "print(f'üìÅ Artifacts directory: {ARTIFACTS_DIR.absolute()}')\n",
    "if HAS_UMAP:\n",
    "    print('‚úÖ UMAP available - will use for faster embedding')\n",
    "else:\n",
    "    print('‚ö†Ô∏è UMAP not available - will use t-SNE (may be slower)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Loading the Cleaned Dataset\n",
    "\n",
    "**Important**: Run `01-Data_Extraction.ipynb` first to generate the cleaned dataset!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the cleaned dataset (preprocessed in 01-Data_Extraction.ipynb)\n",
    "DATA_PATH = Path('artifacts/presets_final.csv')\n",
    "\n",
    "if not DATA_PATH.exists():\n",
    "    print(\"‚ö†Ô∏è Cleaned dataset not found!\")\n",
    "    print(\"   Please run Data_Extraction.ipynb first to generate:\")\n",
    "    print(f\"   {DATA_PATH}\")\n",
    "    raise FileNotFoundError(f\"Run 01-Data_Extraction.ipynb first!\")\n",
    "\n",
    "df = pd.read_csv(DATA_PATH)\n",
    "\n",
    "print(f\"üìä Dataset loaded: {len(df):,} presets\")\n",
    "print(f\"üìã Columns: {len(df.columns)}\")\n",
    "print(f\"üéÆ Unique games: {df['Game'].nunique():,}\")\n",
    "print(f\"\\nFirst few rows:\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PARTE III: EXPLORATION AND ANALYSIS\n",
    "\n",
    "## 6. Parameters Analysis\n",
    "\n",
    "Now let's analyze the key parameters that define each preset's sound. We'll focus on:\n",
    "\n",
    "- **CON (Algorithm)**: Defines the FM synthesis topology (0-7)\n",
    "- **FL (Feedback)**: Controls automodulation of operator 1 (0-7)\n",
    "- **TL (Total Level)**: Volume/mix of each operator\n",
    "- **MUL (Multiplier)**: Frequency ratio per operator\n",
    "- **AR (Attack Rate)**: How percussive vs smooth the sound is\n",
    "- **DT1/DT2 (Detuning)**: Adds richness and chorus effects\n",
    "\n",
    "Plus derived features that combine these parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 CON (Algorithm): The Sound Architecture\n",
    "\n",
    "The Algorithm defines **how operators connect** - the \"blueprint\" of each sound.\n",
    "\n",
    "| Algorithm | Structure | Best For |\n",
    "|-----------|-----------|----------|\n",
    "| 0-2 | Serial chain | Complex evolving pads |\n",
    "| 3-5 | Mixed routing | Rich leads, basses |\n",
    "| 6-7 | Parallel | Organ-like, chords |\n",
    "\n",
    "üìä **Pattern discovery**: Which algorithm was most popular reveals the \"default sound\" of an era."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 FL (Feedback): The Wild Card\n",
    "\n",
    "Feedback = operator modulating **itself**. Powerful but tricky.\n",
    "\n",
    "| FL Value | Sound Character |\n",
    "|----------|-----------------|\n",
    "| 0 | Clean, predictable |\n",
    "| 1-3 | Metallic, bell-like |\n",
    "| 4-5 | Bright, edgy |\n",
    "| 6-7 | Chaotic, noise-like |\n",
    "\n",
    "üéµ **Fun fact**: Yuzo Koshiro's punchy Streets of Rage bass? Creative feedback use!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze key parameters\n",
    "print(\"üéπ Key Parameter Distributions:\\n\")\n",
    "\n",
    "# Algorithm (CON) distribution\n",
    "print(\"Algorithm (CON) Distribution:\")\n",
    "con_dist = df['CON'].value_counts().sort_index()\n",
    "print(con_dist)\n",
    "print()\n",
    "\n",
    "# Feedback (FL) distribution\n",
    "print(\"Feedback (FL) Distribution:\")\n",
    "fl_dist = df['FL'].value_counts().sort_index()\n",
    "print(fl_dist)\n",
    "print()\n",
    "\n",
    "# Visualize both\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "# CON distribution - Kasser Synths theme\n",
    "axes[0].bar(con_dist.index, con_dist.values, color=KASSER_COLORS['primary'], edgecolor='white', linewidth=1.5)\n",
    "axes[0].set_title('Algorithm (CON) Distribution', color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Algorithm (0-7)', color=KASSER_COLORS['text'])\n",
    "axes[0].set_ylabel('Count', color=KASSER_COLORS['text'])\n",
    "axes[0].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[0].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[0].spines['bottom'].set_color(KASSER_COLORS['primary'])\n",
    "axes[0].spines['left'].set_color(KASSER_COLORS['primary'])\n",
    "\n",
    "# FL distribution - Kasser Synths theme\n",
    "axes[1].bar(fl_dist.index, fl_dist.values, color=KASSER_COLORS['secondary'], edgecolor='white', linewidth=1.5)\n",
    "axes[1].set_title('Feedback (FL) Distribution', color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Feedback Level (0-7)', color=KASSER_COLORS['text'])\n",
    "axes[1].set_ylabel('Count', color=KASSER_COLORS['text'])\n",
    "axes[1].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[1].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[1].spines['bottom'].set_color(KASSER_COLORS['secondary'])\n",
    "axes[1].spines['left'].set_color(KASSER_COLORS['secondary'])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéõÔ∏è Insights Algorithm & Feedback\n",
    "\n",
    "Algorithm (CON) results point to a clear ‚Äúdefault choice‚Äù in real-world YM2612 game programming: **Algorithm 4** dominates the dataset. This topology effectively gives you **two carrier branches that are summed at the output**, each shaped by its own modulator, so you can think of it as **two FM voices being mixed inside one channel** (two modulated carriers added by amplitude). In practice, that‚Äôs an incredibly composer-friendly structure: you get a wide palette (bright + body, attack + sustain, tone + edge) while staying predictable and easy to balance in a busy mix. The other algorithms that show up strongly also make sense musically: **Algorithm 2** is a more complex, ‚Äúinteresting‚Äù chain where modulation becomes layered and intertwined, producing richer and sometimes more unstable spectra; **Algorithm 5** is a classic ‚Äúone modulator feeds multiple carriers‚Äù setup (Op1 modulating Ops 2/3/4 that then sum), great for bright, harmonically dense sounds that still keep multiple audible components; and **Algorithm 0** is the fully serial chain (1‚Üí2‚Üí3‚Üí4), which excels at extreme complexity, metallic edge, and sound-design timbres‚Äîuseful, but harder to control than the more balanced topologies üéπ.\n",
    "\n",
    "The feedback (FL) distribution is even more telling: there are basically **no half-measures**. Presets overwhelmingly choose either **FL = 7** (maximum) or **FL = 0** (none), reflecting how feedback behaves on the YM2612: it‚Äôs not just a subtle ‚Äúcharacter‚Äù knob, it‚Äôs a switch between two worlds ‚ö°. With **maximum feedback**, Operator 1 stops behaving like a clean sine source and becomes a **harmonic/noise generator**, injecting aggression, metallic brightness, grit, and ‚Äúcut‚Äù‚Äîexactly what you need for leads, basses, and percussive attacks that must survive on small speakers and in dense arrangements. With **no feedback**, you keep a **stable, controllable sine-like operator**, ideal as a clean carrier or a precise modulator when you want predictable harmonic placement and smooth envelopes; the dataset suggests composers treated feedback as a deliberate stylistic commitment rather than a parameter to gently ‚Äúfine tune‚Äù üéß.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Feature Engineering: Brightness Index & Complexity Score\n",
    "\n",
    "Let's create composite features that capture higher-level characteristics:\n",
    "\n",
    "- **Brightness Index**: Combines TL, AR, and MUL to indicate how \"bright\" or \"shiny\" a sound is\n",
    "- **Complexity Score**: Based on algorithm and number of active operators\n",
    "\n",
    "üí° **Key insight**: Transforming raw parameters into meaningful metrics unlocks deeper analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate derived features\n",
    "\n",
    "# Brightness Index: Higher TL + Higher AR + Higher MUL = brighter sound\n",
    "# Normalize each component to 0-1 scale, then combine\n",
    "def calculate_brightness_index(row):\n",
    "    \"\"\"Calculate brightness index from TL, AR, and MUL parameters\"\"\"\n",
    "    # Average TL across all operators (inverted because lower TL = brighter)\n",
    "    avg_tl = (row['M1_TL'] + row['C1_TL'] + row['M2_TL'] + row['C2_TL']) / 4\n",
    "    tl_score = 1 - (avg_tl / 127)  # Normalize to 0-1, invert\n",
    "    \n",
    "    # Average AR across all operators (higher AR = brighter/percussive)\n",
    "    avg_ar = (row['M1_AR'] + row['C1_AR'] + row['M2_AR'] + row['C2_AR']) / 4\n",
    "    ar_score = avg_ar / 31  # Normalize to 0-1\n",
    "    \n",
    "    # Average MUL across all operators (higher MUL = brighter harmonics)\n",
    "    avg_mul = (row['M1_MUL'] + row['C1_MUL'] + row['M2_MUL'] + row['C2_MUL']) / 4\n",
    "    mul_score = avg_mul / 15  # Normalize to 0-1\n",
    "    \n",
    "    # Weighted combination (clamped to 0-1 range)\n",
    "    brightness = (tl_score * 0.4 + ar_score * 0.3 + mul_score * 0.3)\n",
    "    return max(0, min(1, brightness))\n",
    "\n",
    "# Complexity Score: Based on algorithm and active operators\n",
    "def calculate_complexity_score(row):\n",
    "    \"\"\"Calculate complexity score from algorithm and operator usage\"\"\"\n",
    "    # Algorithm complexity (higher CON = more complex routing)\n",
    "    alg_score = row['CON'] / 7  # Normalize to 0-1\n",
    "    \n",
    "    # Count active operators (TL < 127 means operator is used)\n",
    "    active_ops = sum([\n",
    "        row['M1_TL'] < 127,\n",
    "        row['C1_TL'] < 127,\n",
    "        row['M2_TL'] < 127,\n",
    "        row['C2_TL'] < 127\n",
    "    ])\n",
    "    op_score = active_ops / 4  # Normalize to 0-1\n",
    "    \n",
    "    # Feedback adds complexity\n",
    "    fb_score = row['FL'] / 7  # Normalize to 0-1\n",
    "    \n",
    "    # Weighted combination\n",
    "    complexity = (alg_score * 0.4 + op_score * 0.4 + fb_score * 0.2)\n",
    "    return complexity\n",
    "\n",
    "# Apply calculations\n",
    "df['Brightness_Index'] = df.apply(calculate_brightness_index, axis=1)\n",
    "df['Complexity_Score'] = df.apply(calculate_complexity_score, axis=1)\n",
    "\n",
    "# Visualize derived features - Kasser Synths theme\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5), facecolor=KASSER_COLORS['background'])\n",
    "\n",
    "axes[0].hist(df['Brightness_Index'], bins=50, color=KASSER_COLORS['primary'], edgecolor='white', alpha=0.7, linewidth=0.5)\n",
    "axes[0].set_title('Brightness Index Distribution', color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Brightness Index (0-1)', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[0].set_ylabel('Frequency', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[0].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[0].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[0].spines['bottom'].set_color(KASSER_COLORS['primary'])\n",
    "axes[0].spines['left'].set_color(KASSER_COLORS['primary'])\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "\n",
    "axes[1].hist(df['Complexity_Score'], bins=50, color=KASSER_COLORS['secondary'], edgecolor='white', alpha=0.7, linewidth=0.5)\n",
    "axes[1].set_title('Complexity Score Distribution', color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Complexity Score (0-1)', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[1].set_ylabel('Frequency', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[1].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[1].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[1].spines['bottom'].set_color(KASSER_COLORS['secondary'])\n",
    "axes[1].spines['left'].set_color(KASSER_COLORS['secondary'])\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìä Derived Features Summary:\")\n",
    "print(df[['Brightness_Index', 'Complexity_Score']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üåà Brightness & Complexity: Interpreting Higher-Level FM Characteristics\n",
    "\n",
    "The **Brightness Index** distribution reveals a strong and very deliberate clustering around **mid-to-high values (‚âà 0.55‚Äì0.7)**. This tells us that YM2612 presets used in games were rarely dark or dull by default; instead, composers consistently pushed sounds toward clarity and shine ‚ú®. Since this index combines **TL (output level), AR (attack rate), and MUL (frequency multiplier)**, a higher brightness reflects faster attacks, stronger harmonic emphasis, and more energetic spectra. Historically, this makes perfect sense: on consumer TVs and small speakers, darker FM tones tend to disappear, while brighter sounds cut through the mix. What‚Äôs interesting is that the distribution is not maxed out at 1.0‚Äîcomposers were not chasing pure harshness, but rather a **controlled brightness sweet spot** that balanced presence with musicality.\n",
    "\n",
    "The **Complexity Score** distribution paints a complementary picture üß†. Values are heavily concentrated in the **upper-mid range (‚âà 0.6‚Äì0.85)**, indicating that most presets relied on **multiple active operators and moderately complex algorithms**, rather than minimal or extreme configurations. This suggests a strong preference for **rich internal motion**‚Äîenough operator interaction to create evolving timbres, but not so much that the sound becomes unstable or noisy. Very low-complexity sounds (simple, almost subtractive-like FM patches) are rare, reinforcing the idea that YM2612 was primarily used as a **characterful synthesis engine**, not just a sine generator. At the same time, the avoidance of the absolute maximum complexity hints at a practical mindset: composers wanted depth and texture, but still needed predictable behavior, fast programming, and reliable playback during gameplay üéÆ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Games Signatures\n",
    "\n",
    "**What Makes a Game's Sound Unique?**\n",
    "Each game has a \"sonic signature\"‚Äîa combination of parameter choices that creates its distinctive sound. *Streets of Rage* sounds different from *Sonic the Hedgehog* not just because of the melodies, but because of the **sound design choices** made by the composers.\n",
    "\n",
    "**Why Analyze by Game?**\n",
    "Games are **natural groupings** in our data. All presets from \"Sonic the Hedgehog\" share a common context: they were created by the same team, for the same project, with the same artistic vision. By analyzing games, we can:\n",
    "- Identify which games had the most creative sound design\n",
    "- Find games with similar sonic palettes (maybe they shared composers or tools)\n",
    "- Understand how different genres approached FM synthesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_series(s: pd.Series):\n",
    "    \"\"\"Return the mode (most frequent) for a Series; ties -> smallest value.\"\"\"\n",
    "    s = s.dropna()\n",
    "    if len(s) == 0:\n",
    "        return np.nan\n",
    "    vc = s.value_counts()\n",
    "    top_count = vc.iloc[0]\n",
    "    modes = vc[vc == top_count].index.tolist()\n",
    "    return min(modes)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Analyze presets by game (mode-only for CON/FL)\n",
    "# -------------------------------\n",
    "game_stats = (\n",
    "    df.groupby('Game')\n",
    "      .agg(\n",
    "          CON_Mode=('CON', mode_series),\n",
    "          FL_Mode=('FL', mode_series),\n",
    "\n",
    "          Brightness_Mean=('Brightness_Index', 'mean'),\n",
    "          Brightness_Std=('Brightness_Index', 'std'),\n",
    "          Complexity_Mean=('Complexity_Score', 'mean'),\n",
    "          Complexity_Std=('Complexity_Score', 'std'),\n",
    "\n",
    "          Preset_Count=('Filename', 'count')\n",
    "      )\n",
    ")\n",
    "\n",
    "# Round numeric columns nicely\n",
    "round_cols = [\n",
    "    'CON_Mode', 'FL_Mode',\n",
    "    'Brightness_Mean', 'Brightness_Std',\n",
    "    'Complexity_Mean', 'Complexity_Std'\n",
    "]\n",
    "for c in round_cols:\n",
    "    if c in game_stats.columns:\n",
    "        game_stats[c] = game_stats[c].round(2)\n",
    "\n",
    "# Get top games by preset count\n",
    "top_games_list = df['Game'].value_counts().head(20).index.tolist()\n",
    "\n",
    "print(\"üéÆ Top 20 Games Analysis (mode-only CON/FL):\")\n",
    "print(game_stats.loc[top_games_list].sort_values('Preset_Count', ascending=False))\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# Visualize algorithm distribution + brightness for top 10 by preset count\n",
    "# -------------------------------\n",
    "fig, axes = plt.subplots(2, 1, figsize=(14, 10))\n",
    "\n",
    "top_10_games = top_games_list[:10]\n",
    "subset = df[df['Game'].isin(top_10_games)]\n",
    "\n",
    "# Algorithm (CON) distribution by game\n",
    "con_by_game = pd.crosstab(subset['Game'], subset['CON'])\n",
    "con_by_game_pct = con_by_game.div(con_by_game.sum(axis=1), axis=0) * 100\n",
    "\n",
    "kasser_palette = [\n",
    "    KASSER_COLORS['primary'], KASSER_COLORS['secondary'], KASSER_COLORS['tertiary'],\n",
    "    KASSER_COLORS['accent'], '#00d4ff', '#ff0080', '#00ff88', '#cc00ff'\n",
    "]\n",
    "con_by_game_pct.plot(kind='bar', ax=axes[0], color=kasser_palette[:8],\n",
    "                     edgecolor='white', linewidth=1)\n",
    "\n",
    "axes[0].set_title('Algorithm (CON) Distribution by Top 10 Games',\n",
    "                  color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Game', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[0].set_ylabel('Percentage (%)', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[0].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[0].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[0].spines['bottom'].set_color(KASSER_COLORS['primary'])\n",
    "axes[0].spines['left'].set_color(KASSER_COLORS['primary'])\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].legend(title='Algorithm', title_fontsize=9, fontsize=8,\n",
    "               facecolor=KASSER_COLORS['background'], edgecolor=KASSER_COLORS['primary'],\n",
    "               labelcolor=KASSER_COLORS['text'], framealpha=0.9)\n",
    "axes[0].tick_params(axis='x', rotation=45)\n",
    "\n",
    "# Brightness Index by game (top 10 by presets)\n",
    "brightness_by_game = (\n",
    "    subset.groupby('Game')['Brightness_Index']\n",
    "          .mean()\n",
    "          .sort_values()\n",
    ")\n",
    "brightness_by_game.plot(kind='barh', ax=axes[1], color=KASSER_COLORS['primary'],\n",
    "                        edgecolor='white', linewidth=1)\n",
    "\n",
    "axes[1].set_title('Average Brightness Index by Top 10 Games',\n",
    "                  color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Brightness Index', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[1].set_ylabel('Game', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[1].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[1].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[1].spines['bottom'].set_color(KASSER_COLORS['primary'])\n",
    "axes[1].spines['left'].set_color(KASSER_COLORS['primary'])\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# NEW: Top 10 least bright games (global)\n",
    "# -------------------------------\n",
    "least_bright = (\n",
    "    df[df['Game'].notna()]\n",
    "      .groupby('Game')['Brightness_Index']\n",
    "      .mean()\n",
    "      .sort_values()\n",
    "      .head(10)\n",
    ")\n",
    "\n",
    "fig2, ax2 = plt.subplots(1, 1, figsize=(14, 6))\n",
    "least_bright.plot(kind='barh', ax=ax2, color=KASSER_COLORS['secondary'],\n",
    "                  edgecolor='white', linewidth=1)\n",
    "\n",
    "ax2.set_title('Top 10 Least Bright Games (Average Brightness Index)',\n",
    "              color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "ax2.set_xlabel('Brightness Index', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "ax2.set_ylabel('Game', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "ax2.set_facecolor(KASSER_COLORS['background'])\n",
    "ax2.tick_params(colors=KASSER_COLORS['text'])\n",
    "ax2.spines['bottom'].set_color(KASSER_COLORS['primary'])\n",
    "ax2.spines['left'].set_color(KASSER_COLORS['primary'])\n",
    "ax2.spines['top'].set_visible(False)\n",
    "ax2.spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Algorithm (CON) Distribution by Top Games\n",
    "\n",
    "The first chart shows that, while there‚Äôs a shared ‚ÄúYM2612 grammar,‚Äù each game ends up with a very recognizable **algorithm fingerprint**. Across almost all titles, **Algorithm 4** repeatedly rises to the top, reinforcing it as the most dependable and musically flexible routing‚Äîeffectively letting composers layer *two FM voices inside one channel* and balance body with edge. At the same time, the differences between games are striking: **Pulseman** is an extreme case with one algorithm dominating most of its presets, which fits its aggressive, electronic/techno-leaning sound design ‚ö°. By contrast, titles like **Gunstar Heroes**, **Streets of Rage 3**, and **Thunder Force IV** spread their usage across several algorithms, suggesting broader instrument variety and more deliberate ‚Äúrouting choices‚Äù per patch rather than a single default. In other words: some scores build a signature sound by committing to one topology, while others get their identity from constantly switching FM structures üéπ.\n",
    "\n",
    "## üåà Average Brightness Index by Top Games\n",
    "\n",
    "The second chart highlights a strong convergence: these games cluster tightly in a **mid-to-high Brightness Index range**, with no one living in the ‚Äúdark‚Äù zone. That‚Äôs a very practical outcome of Genesis-era realities‚Äîpatches needed enough bite to stay audible through small TV speakers and dense mixes, but not so much brightness that the soundtrack becomes fatiguing. **The Adventures of Batman and Robin** and **Pulseman** sit at the bright end, matching their reputation for sharp, punchy, high-energy timbres ‚ú®, while **Ristar** and **Sonic 3 & Knuckles** sit a bit lower, consistent with a slightly rounder, more melodic palette that still preserves clarity. Overall, it suggests composers converged on a **safe brightness sweet spot**: bright enough to cut, controlled enough to stay musical üéÆ.\n",
    "\n",
    "## üåë Top 10 Least Bright Games ‚Äî A Different FM Aesthetic\n",
    "\n",
    "This chart highlights a small but very telling group of games that deliberately sit at the **low end of the Brightness Index**, clearly breaking away from the Genesis norm of bright, cutting FM sounds. Titles like *Thunder Pro Wrestling Retsuden*, *The Tick*, *Tinhead*, or *Top Gear 2* favor noticeably darker patches, suggesting a sound design approach where **warmth, weight, and atmosphere** take priority over immediacy and bite. In many of these cases‚Äîespecially racing games and sports titles‚Äîthe music benefits from a **less aggressive spectral profile**, allowing groove, rhythm, and low‚Äìmid energy to dominate without competing harshly with sound effects. From a technical perspective, this likely translates to lower operator output levels, slower attacks, and fewer high multipliers, resulting in smoother, more subdued FM tones. Historically, these games often relied more heavily on PCM drums or strong bass lines, reducing the need for extremely bright FM voices. The existence of this cluster confirms that while high brightness was the Genesis ‚Äúdefault,‚Äù experienced composers selectively rejected it when the game‚Äôs mood, genre, or pacing demanded a darker, more restrained sonic identity üéÆ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Dimensionality Reduction\n",
    "\n",
    "**The Challenge**: 58 parameters = impossible to visualize  \n",
    "**The Solution**: Reduce dimensions while preserving relationships\n",
    "\n",
    "We'll use:\n",
    "- **PCA** for initial compression (58D ‚Üí 50D)\n",
    "- **t-SNE** or **UMAP** for 2D embedding (50D ‚Üí 2D)\n",
    "- **Clustering** to identify natural groups\n",
    "\n",
    "**Visualization Colors:**\n",
    "- Algorithm (CON)\n",
    "- Feedback (FL)\n",
    "- Game\n",
    "- Brightness Index\n",
    "- Complexity Score\n",
    "- (Later: Composer, Nationality)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.1 PCA: Compressing 58 Dimensions\n",
    "\n",
    "**The problem**: 58 parameters = impossible to visualize  \n",
    "**The solution**: PCA finds the \"most important\" directions in the data\n",
    "\n",
    "| Step | What happens |\n",
    "|------|--------------|\n",
    "| 1 | Find direction of maximum variance |\n",
    "| 2 | Find perpendicular directions |\n",
    "| 3 | Keep top N components (~50 = 95% info) |\n",
    "\n",
    "üìâ **Result**: 58D ‚Üí 50D with minimal information loss. Many parameters are correlated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# PREPARE FEATURE MATRIX AND SCALER (with caching)\n",
    "# ============================================================================\n",
    "SCALER_CACHE = ARTIFACTS_DIR / 'scaler.joblib'\n",
    "X_SCALED_CACHE = ARTIFACTS_DIR / 'X_scaled.joblib'\n",
    "FEATURE_COLS_CACHE = ARTIFACTS_DIR / 'feature_columns.json'\n",
    "\n",
    "# Exclude metadata and derived features for now (we'll add them back for coloring)\n",
    "feature_cols = [col for col in df.columns \n",
    "                if col not in ['Num', 'Name', 'Filename', 'Game', 'Uses_GEMS', 'Composer', 'Nationality', 'Brightness_Index', 'Complexity_Score']]\n",
    "\n",
    "print(f\"üìä Feature columns: {len(feature_cols)}\")\n",
    "print(f\"Sample features: {feature_cols[:10]}\")\n",
    "\n",
    "# Check if cached scaler exists and matches\n",
    "cache_valid = False\n",
    "if SCALER_CACHE.exists() and X_SCALED_CACHE.exists():\n",
    "    scaler = joblib.load(SCALER_CACHE)\n",
    "    X_scaled = joblib.load(X_SCALED_CACHE)\n",
    "    if X_scaled.shape[0] == len(df) and X_scaled.shape[1] == len(feature_cols):\n",
    "        cache_valid = True\n",
    "        print(f\"‚úÖ Loaded cached scaler and X_scaled: {X_scaled.shape}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Cache size mismatch, recomputing...\")\n",
    "\n",
    "if not cache_valid:\n",
    "    # Create feature matrix\n",
    "    X = df[feature_cols].values.astype(np.float32)\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    # Save to cache immediately\n",
    "    joblib.dump(scaler, SCALER_CACHE)\n",
    "    joblib.dump(X_scaled, X_SCALED_CACHE)\n",
    "    with open(FEATURE_COLS_CACHE, 'w') as f:\n",
    "        json.dump(feature_cols, f, indent=2)\n",
    "    print(f\"üíæ Saved scaler and X_scaled to cache\")\n",
    "\n",
    "print(f\"\\n‚úÖ Feature matrix ready: {X_scaled.shape}\")\n",
    "print(f\"   Mean (first 5 dims): {X_scaled.mean(axis=0)[:5]}\")\n",
    "print(f\"   Std  (first 5 dims): {X_scaled.std(axis=0)[:5]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# APPLY PCA (with caching)\n",
    "# ============================================================================\n",
    "PCA_MODEL_CACHE = ARTIFACTS_DIR / 'pca_model.joblib'\n",
    "X_PCA_CACHE = ARTIFACTS_DIR / 'X_pca.joblib'\n",
    "\n",
    "# Check if cached PCA exists and matches\n",
    "cache_valid = False\n",
    "if PCA_MODEL_CACHE.exists() and X_PCA_CACHE.exists():\n",
    "    pca = joblib.load(PCA_MODEL_CACHE)\n",
    "    X_pca = joblib.load(X_PCA_CACHE)\n",
    "    if X_pca.shape[0] == len(X_scaled):\n",
    "        cache_valid = True\n",
    "        print(f'‚úÖ Loaded cached PCA model and X_pca: {X_pca.shape}')\n",
    "    else:\n",
    "        print(f'‚ö†Ô∏è Cache size mismatch, recomputing...')\n",
    "\n",
    "if not cache_valid:\n",
    "    # Apply PCA\n",
    "    pca = PCA(n_components=50, random_state=42)\n",
    "    X_pca = pca.fit_transform(X_scaled)\n",
    "    \n",
    "    # Save to cache immediately\n",
    "    joblib.dump(pca, PCA_MODEL_CACHE)\n",
    "    joblib.dump(X_pca, X_PCA_CACHE)\n",
    "    print(f'üíæ Saved PCA model and X_pca to cache')\n",
    "\n",
    "# Calculate cumulative variance\n",
    "cumvar = np.cumsum(pca.explained_variance_ratio_)\n",
    "k95 = int(np.searchsorted(cumvar, 0.95) + 1)\n",
    "\n",
    "print(f\"üìä PCA Results:\")\n",
    "print(f\"   Components: {X_pca.shape[1]}\")\n",
    "print(f\"   Components for 95% variance: {k95}\")\n",
    "print(f\"   Variance explained by first 10 components: {cumvar[9]:.2%}\")\n",
    "\n",
    "# Visualize variance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "\n",
    "axes[0].plot(range(1, min(51, len(cumvar) + 1)), cumvar[:50], color=KASSER_COLORS['primary'], linewidth=2.5)\n",
    "axes[0].axhline(0.95, color=KASSER_COLORS['secondary'], linestyle='--', linewidth=2, label='95% variance')\n",
    "axes[0].axvline(k95, color=KASSER_COLORS['secondary'], linestyle='--', alpha=0.7, linewidth=2)\n",
    "axes[0].set_title('PCA Explained Variance', color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[0].set_xlabel('Number of Components', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[0].set_ylabel('Cumulative Explained Variance', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[0].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[0].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[0].spines['bottom'].set_color(KASSER_COLORS['primary'])\n",
    "axes[0].spines['left'].set_color(KASSER_COLORS['primary'])\n",
    "axes[0].spines['top'].set_visible(False)\n",
    "axes[0].spines['right'].set_visible(False)\n",
    "axes[0].legend(facecolor=KASSER_COLORS['background'], edgecolor=KASSER_COLORS['primary'], \n",
    "               labelcolor=KASSER_COLORS['text'], framealpha=0.9)\n",
    "axes[0].grid(True, alpha=0.2, color=KASSER_COLORS['primary'])\n",
    "\n",
    "axes[1].bar(range(1, 11), pca.explained_variance_ratio_[:10], color=KASSER_COLORS['secondary'], edgecolor='white', linewidth=1)\n",
    "axes[1].set_title('First 10 Components Variance', color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[1].set_xlabel('Component', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[1].set_ylabel('Explained Variance Ratio', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[1].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[1].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[1].spines['bottom'].set_color(KASSER_COLORS['secondary'])\n",
    "axes[1].spines['left'].set_color(KASSER_COLORS['secondary'])\n",
    "axes[1].spines['top'].set_visible(False)\n",
    "axes[1].spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8.2 t-SNE/UMAP: Making the Invisible Visible\n",
    "\n",
    "50D ‚Üí 2D while preserving relationships. **Similar sounds = close points**.\n",
    "\n",
    "| Algorithm | Strengths |\n",
    "|-----------|-----------|\n",
    "| **t-SNE** | Great clusters, reveals local structure |\n",
    "| **UMAP** | Faster, better global structure |\n",
    "\n",
    "üé® **Color by**: Algorithm, Game, Brightness, Composer ‚Üí different patterns emerge!\n",
    "\n",
    "üíæ **Caching**: Results are saved to `artifacts/` after computation. If the cache exists, it will be loaded instead of recomputing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if UMAP is available (faster alternative)\n",
    "try:\n",
    "    import umap\n",
    "    HAS_UMAP = True\n",
    "    print(\"‚úÖ UMAP available - will use for faster embedding\")\n",
    "except ImportError:\n",
    "    HAS_UMAP = False\n",
    "    print(\"‚ö†Ô∏è UMAP not available - will use t-SNE (may be slower)\")\n",
    "\n",
    "# Use FULL dataset (no sampling)\n",
    "USE_SAMPLE = False  # We use the complete dataset\n",
    "X_embed = X_pca\n",
    "df_embed = df.copy()\n",
    "\n",
    "print(f\"üìä Using FULL dataset: {len(df):,} presets\")\n",
    "print(f\"‚úÖ Ready for embedding: {X_embed.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# COMPUTE 2D EMBEDDING (with caching)\n",
    "# ============================================================================\n",
    "EMBEDDING_CACHE = ARTIFACTS_DIR / 'embedding_2d.joblib'\n",
    "EMBEDDING_METHOD_CACHE = ARTIFACTS_DIR / 'embedding_method.txt'\n",
    "\n",
    "# Check if cached embedding exists and matches dataset size\n",
    "cache_valid = False\n",
    "if EMBEDDING_CACHE.exists():\n",
    "    cached_embedding = joblib.load(EMBEDDING_CACHE)\n",
    "    if len(cached_embedding) == len(X_embed):\n",
    "        cache_valid = True\n",
    "        embedding = cached_embedding\n",
    "        method = EMBEDDING_METHOD_CACHE.read_text().strip() if EMBEDDING_METHOD_CACHE.exists() else 'cached'\n",
    "        print(f\"‚úÖ Loaded cached {method} embedding: {embedding.shape}\")\n",
    "    else:\n",
    "        print(f\"‚ö†Ô∏è Cache size mismatch ({len(cached_embedding)} vs {len(X_embed)}), recomputing...\")\n",
    "\n",
    "if not cache_valid:\n",
    "    print(\"üîÑ Computing 2D embedding... (this may take a while for full dataset)\")\n",
    "    print(f\"   Dataset size: {len(X_embed):,} presets\")\n",
    "    \n",
    "    if HAS_UMAP:\n",
    "        reducer = umap.UMAP(\n",
    "            n_neighbors=30,\n",
    "            min_dist=0.05,\n",
    "            n_components=2,\n",
    "            metric='euclidean',\n",
    "            random_state=42,\n",
    "            verbose=True\n",
    "        )\n",
    "        embedding = reducer.fit_transform(X_embed)\n",
    "        method = \"UMAP\"\n",
    "    else:\n",
    "        # Use t-SNE\n",
    "        perplexity = min(30, max(5, (len(X_embed) - 1) // 3))\n",
    "        tsne = TSNE(\n",
    "            n_components=2,\n",
    "            perplexity=perplexity,\n",
    "            init='pca',\n",
    "            learning_rate='auto',\n",
    "            random_state=42,\n",
    "            n_iter=1000,\n",
    "            verbose=1\n",
    "        )\n",
    "        embedding = tsne.fit_transform(X_embed)\n",
    "        method = \"t-SNE\"\n",
    "    \n",
    "    # Save to cache immediately\n",
    "    joblib.dump(embedding, EMBEDDING_CACHE)\n",
    "    EMBEDDING_METHOD_CACHE.write_text(method)\n",
    "    print(f\"üíæ Saved embedding to cache: {EMBEDDING_CACHE}\")\n",
    "\n",
    "print(f\"‚úÖ {method} embedding ready!\")\n",
    "print(f\"   Shape: {embedding.shape}\")\n",
    "\n",
    "# Add embedding coordinates to dataframe\n",
    "df_embed['embed_x'] = embedding[:, 0]\n",
    "df_embed['embed_y'] = embedding[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create interactive plotly visualizations\n",
    "def plot_embedding(df_embed, color_by, title, colorscale='Viridis'):\n",
    "    \"\"\"Create interactive scatter plot of embedding\"\"\"\n",
    "    # Kasser Synths color scale for continuous data\n",
    "    kasser_continuous_scale = [[0, KASSER_COLORS['background']], \n",
    "                                [0.5, KASSER_COLORS['primary']], \n",
    "                                [1, KASSER_COLORS['secondary']]]\n",
    "    \n",
    "    # Use Kasser Synths colors for continuous scales\n",
    "    if isinstance(df_embed[color_by].dtype, (np.number, pd.Series)) and df_embed[color_by].dtype != 'object':\n",
    "        colorscale_to_use = kasser_continuous_scale\n",
    "    else:\n",
    "        colorscale_to_use = None\n",
    "    \n",
    "    fig = px.scatter(\n",
    "        df_embed,\n",
    "        x='embed_x',\n",
    "        y='embed_y',\n",
    "        color=color_by,\n",
    "        title=title,\n",
    "        labels={color_by: color_by.replace('_', ' ')},\n",
    "        hover_data=['Name', 'Game', 'CON', 'FL'],\n",
    "        color_continuous_scale=colorscale_to_use,\n",
    "        width=1000,\n",
    "        height=700\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=KASSER_COLORS['background'],\n",
    "        paper_bgcolor=KASSER_COLORS['background'],\n",
    "        font_color=KASSER_COLORS['text'],\n",
    "        title_font_size=16,\n",
    "        title_font_color=KASSER_COLORS['text'],\n",
    "        font_family='sans-serif'\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=3, opacity=0.6))\n",
    "    return fig\n",
    "\n",
    "# Visualize by Algorithm (CON)\n",
    "print(\"üìä Creating visualizations...\")\n",
    "fig1 = plot_embedding(df_embed, 'CON', f'2D Embedding Colored by Algorithm (CON) - {method}')\n",
    "fig1.show()\n",
    "\n",
    "# Visualize by Feedback (FL)\n",
    "fig2 = plot_embedding(df_embed, 'FL', f'2D Embedding Colored by Feedback (FL) - {method}')\n",
    "fig2.show()\n",
    "\n",
    "# Visualize by Brightness Index\n",
    "fig3 = plot_embedding(df_embed, 'Brightness_Index', f'2D Embedding Colored by Brightness Index - {method}', 'Plasma')\n",
    "fig3.show()\n",
    "\n",
    "# Visualize by Complexity Score\n",
    "fig4 = plot_embedding(df_embed, 'Complexity_Score', f'2D Embedding Colored by Complexity Score - {method}', 'Cividis')\n",
    "fig4.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Clustering: Natural Groups\n",
    "\n",
    "**What is Clustering?**\n",
    "Clustering is **unsupervised learning**‚Äîfinding groups in data without labels. We're not telling the algorithm \"these are bass sounds, these are leads\"; instead, we're asking \"what natural groups exist?\"\n",
    "\n",
    "**KMeans Clustering:**\n",
    "- **K = number of clusters**: We'll use the **Elbow Method** to find the optimal number automatically\n",
    "- **Centroid-based**: Each cluster has a \"center\" (the average preset in that cluster)\n",
    "- **Iterative**: The algorithm moves cluster centers until presets are optimally grouped\n",
    "\n",
    "**The Elbow Method:**\n",
    "The elbow method helps us find the optimal number of clusters by:\n",
    "1. Running KMeans for different values of K (2 to 15)\n",
    "2. Calculating the **inertia** (sum of squared distances to cluster centers) for each K\n",
    "3. Finding the \"elbow point\" where adding more clusters gives diminishing returns\n",
    "\n",
    "We'll use the elbow point directly as our optimal K value (defaulting to K=7 if detection fails)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# ELBOW METHOD: Finding the Optimal Number of Clusters (with caching)\n",
    "# ============================================================================\n",
    "from kneed import KneeLocator  # For automatic elbow detection\n",
    "\n",
    "ELBOW_CACHE = ARTIFACTS_DIR / 'elbow_results.joblib'\n",
    "\n",
    "# Check if cached elbow results exist\n",
    "cache_valid = False\n",
    "if ELBOW_CACHE.exists():\n",
    "    elbow_data = joblib.load(ELBOW_CACHE)\n",
    "    if elbow_data.get('n_samples') == len(X_scaled):\n",
    "        cache_valid = True\n",
    "        inertias = elbow_data['inertias']\n",
    "        elbow_k = elbow_data['elbow_k']\n",
    "        K_range = range(2, 16)\n",
    "        print(f'‚úÖ Loaded cached elbow results: elbow_k = {elbow_k}')\n",
    "    else:\n",
    "        print(f'‚ö†Ô∏è Cache size mismatch, recomputing...')\n",
    "\n",
    "if not cache_valid:\n",
    "    print('üîÑ Running Elbow Method to find optimal number of clusters...')\n",
    "    print(f'   Using FULL dataset: {len(X_scaled):,} presets')\n",
    "    \n",
    "    # Use FULL dataset (no sampling)\n",
    "    X_cluster = X_scaled\n",
    "    \n",
    "    # Test different values of K\n",
    "    K_range = range(2, 16)\n",
    "    inertias = []\n",
    "    \n",
    "    print(f'   Testing K from {K_range.start} to {K_range.stop - 1}...')\n",
    "    for k in K_range:\n",
    "        kmeans_temp = KMeans(n_clusters=k, init='k-means++', random_state=42, n_init=10)\n",
    "        kmeans_temp.fit(X_cluster)\n",
    "        inertias.append(kmeans_temp.inertia_)\n",
    "        print(f'   K={k}: Inertia = {kmeans_temp.inertia_:,.0f}')\n",
    "    \n",
    "    # Find the elbow point automatically using KneeLocator\n",
    "    kneedle = KneeLocator(list(K_range), inertias, curve='convex', direction='decreasing')\n",
    "    elbow_k = kneedle.elbow if kneedle.elbow else 7  # Default to 7 if no elbow found\n",
    "    \n",
    "    # Save to cache\n",
    "    joblib.dump({\n",
    "        'inertias': inertias,\n",
    "        'elbow_k': elbow_k,\n",
    "        'n_samples': len(X_scaled)\n",
    "    }, ELBOW_CACHE)\n",
    "    print(f'üíæ Saved elbow results to cache')\n",
    "\n",
    "# Use the elbow value directly (default to 7 if not detected properly)\n",
    "optimal_k = elbow_k if elbow_k else 7\n",
    "\n",
    "print(f\"\\nüìä Elbow Method Results:\")\n",
    "print(f\"   Detected elbow point: K = {elbow_k}\")\n",
    "print(f\"   Using K = {optimal_k} for clustering\")\n",
    "\n",
    "# Plot the Elbow Curve\n",
    "fig_elbow = go.Figure()\n",
    "fig_elbow.add_trace(go.Scatter(\n",
    "    x=list(K_range), y=inertias,\n",
    "    mode='lines+markers',\n",
    "    name='Inertia',\n",
    "    line=dict(color=KASSER_COLORS['primary'], width=2),\n",
    "    marker=dict(size=8)\n",
    "))\n",
    "fig_elbow.add_vline(x=optimal_k, line_dash='dash', line_color=KASSER_COLORS['secondary'],\n",
    "                    annotation_text=f'Elbow (K={optimal_k})', annotation_position='top')\n",
    "fig_elbow.update_layout(\n",
    "    title='Elbow Method: Finding Optimal Number of Clusters',\n",
    "    xaxis_title='Number of Clusters (K)',\n",
    "    yaxis_title='Inertia (Sum of Squared Distances)',\n",
    "    plot_bgcolor=KASSER_COLORS['background'],\n",
    "    paper_bgcolor=KASSER_COLORS['background'],\n",
    "    font_color=KASSER_COLORS['text'],\n",
    "    width=900, height=500\n",
    ")\n",
    "fig_elbow.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# APPLY CLUSTERING WITH OPTIMAL K (from Elbow Method)\n",
    "# ============================================================================\n",
    "\n",
    "CLUSTER_CACHE = ARTIFACTS_DIR / 'cluster_results.joblib'\n",
    "\n",
    "# Extended color palette for up to 15 clusters\n",
    "cluster_colors = [\n",
    "    KASSER_COLORS['primary'], KASSER_COLORS['secondary'], \n",
    "    KASSER_COLORS['tertiary'], KASSER_COLORS['accent'],\n",
    "    '#00d4ff', '#ff0080', '#00ff88', '#cc00ff',\n",
    "    '#00b8d4', '#e91e63', '#4caf50', '#9c27b0',\n",
    "    '#ff5722', '#607d8b', '#795548'\n",
    "]\n",
    "\n",
    "# Check if cached cluster results exist for this K\n",
    "cache_valid = False\n",
    "if CLUSTER_CACHE.exists():\n",
    "    cached_data = joblib.load(CLUSTER_CACHE)\n",
    "    if (cached_data.get('n_samples') == len(X_scaled) and \n",
    "        cached_data.get('optimal_k') == optimal_k):\n",
    "        cache_valid = True\n",
    "        kmeans = cached_data['kmeans']\n",
    "        cluster_labels = cached_data['labels']\n",
    "        print(f'‚úÖ Loaded cached cluster results for K = {optimal_k}')\n",
    "\n",
    "if not cache_valid:\n",
    "    print(f'üîÑ Computing clusters for K = {optimal_k}...')\n",
    "    print(f'   Using FULL dataset: {len(X_scaled):,} presets')\n",
    "    \n",
    "    # Fit KMeans on FULL dataset\n",
    "    kmeans = KMeans(n_clusters=optimal_k, init='k-means++', random_state=42, n_init=10)\n",
    "    cluster_labels = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Save to cache\n",
    "    joblib.dump({\n",
    "        'kmeans': kmeans,\n",
    "        'labels': cluster_labels,\n",
    "        'optimal_k': optimal_k,\n",
    "        'n_samples': len(X_scaled)\n",
    "    }, CLUSTER_CACHE)\n",
    "    print(f'üíæ Saved cluster results to cache')\n",
    "\n",
    "# Apply cluster labels to dataframe\n",
    "df_embed['Cluster'] = cluster_labels\n",
    "\n",
    "print(f\"\\nüéØ Applied K = {optimal_k} clusters\")\n",
    "\n",
    "# Visualize clusters\n",
    "fig_clusters = px.scatter(\n",
    "    df_embed,\n",
    "    x='embed_x',\n",
    "    y='embed_y',\n",
    "    color='Cluster',\n",
    "    title=f'K = {optimal_k} Clusters - {method}',\n",
    "    hover_data=['Name', 'Game', 'CON', 'FL', 'Brightness_Index'],\n",
    "    width=900,\n",
    "    height=600,\n",
    "    color_discrete_sequence=cluster_colors[:optimal_k]\n",
    ")\n",
    "fig_clusters.update_layout(\n",
    "    plot_bgcolor=KASSER_COLORS['background'],\n",
    "    paper_bgcolor=KASSER_COLORS['background'],\n",
    "    font_color=KASSER_COLORS['text'],\n",
    "    title_font_size=16,\n",
    "    title_font_color=KASSER_COLORS['text'],\n",
    "    font_family='sans-serif'\n",
    ")\n",
    "fig_clusters.update_traces(marker=dict(size=3, opacity=0.6))\n",
    "fig_clusters.show()\n",
    "\n",
    "# Analyze cluster characteristics\n",
    "print(\"\\nüìä Cluster Characteristics:\")\n",
    "\n",
    "def mode_1(x):\n",
    "    # mode robusto: ignora NaN, y si hay empate toma el primero (ordenado)\n",
    "    s = x.dropna()\n",
    "    if s.empty:\n",
    "        return np.nan\n",
    "    m = s.mode()\n",
    "    return m.iloc[0] if len(m) else np.nan\n",
    "\n",
    "cluster_stats = df_embed.groupby('Cluster').agg({\n",
    "    'CON': mode_1,                 # MODE\n",
    "    'FL': mode_1,                  # MODE\n",
    "    'Brightness_Index': 'mean',    # AVERAGE\n",
    "    'Complexity_Score': 'mean',    # AVERAGE\n",
    "    'Game': mode_1                 # (opcional) modo del juego tambi√©n\n",
    "})\n",
    "\n",
    "# Redondear solo m√©tricas num√©ricas (evita tocar strings)\n",
    "for col in ['Brightness_Index', 'Complexity_Score']:\n",
    "    if col in cluster_stats.columns:\n",
    "        cluster_stats[col] = cluster_stats[col].astype(float).round(2)\n",
    "\n",
    "cluster_stats = cluster_stats.rename(columns={\n",
    "    'CON': 'Mode_CON',\n",
    "    'FL': 'Mode_FL',\n",
    "    'Brightness_Index': 'Avg_Brightness',\n",
    "    'Complexity_Score': 'Avg_Complexity',\n",
    "    'Game': 'Most_Common_Game'\n",
    "})\n",
    "\n",
    "cluster_stats['Preset_Count'] = df_embed['Cluster'].value_counts().sort_index()\n",
    "\n",
    "print(cluster_stats)\n",
    "\n",
    "\n",
    "# Print cluster sizes\n",
    "print(f'\\nüìä Cluster sizes:')\n",
    "cluster_sizes = pd.Series(cluster_labels).value_counts().sort_index()\n",
    "print(dict(cluster_sizes))\n",
    "print(f'\\nInertia: {kmeans.inertia_:,.0f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Recommendation System\n",
    "\n",
    "**The Power of Nearest Neighbors:**\n",
    "\n",
    "Once we have our high-dimensional feature space, we can find presets that are \"similar\" to any given preset. This is the same technology behind recommendation systems!\n",
    "\n",
    "**How It Works:**\n",
    "- We use **cosine similarity** to measure how \"close\" two presets are in feature space\n",
    "- The algorithm finds the K nearest neighbors (most similar presets)\n",
    "- Similar presets share parameter patterns, even if they're from different games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Nearest Neighbors index\n",
    "print(\"üîÑ Building similarity index...\")\n",
    "\n",
    "# Use cosine similarity (good for normalized features)\n",
    "nn = NearestNeighbors(n_neighbors=20, metric='cosine', algorithm='auto')\n",
    "nn.fit(X_scaled)\n",
    "\n",
    "print(\"‚úÖ Similarity index ready!\")\n",
    "\n",
    "# Function to find similar presets\n",
    "def find_similar_presets(preset_idx, top_k=10):\n",
    "    \"\"\"Find top K similar presets to a given preset\"\"\"\n",
    "    query = X_scaled[preset_idx:preset_idx+1]\n",
    "    distances, indices = nn.kneighbors(query, n_neighbors=top_k+1)  # +1 because first is itself\n",
    "    \n",
    "    # Remove the preset itself (distance = 0)\n",
    "    distances = distances[0][1:]\n",
    "    indices = indices[0][1:]\n",
    "    \n",
    "    # Create results dataframe\n",
    "    results = df.iloc[indices].copy()\n",
    "    results.insert(0, 'Similarity_Score', 1 - distances)  # Convert distance to similarity\n",
    "    results.insert(0, 'Rank', range(1, len(results) + 1))\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Example: Find similar presets to the first preset\n",
    "example_idx = 14500\n",
    "similar = find_similar_presets(example_idx, top_k=10)\n",
    "\n",
    "print(f\"\\nüéµ Preset: {df.iloc[example_idx]['Name']} from {df.iloc[example_idx]['Game']}\")\n",
    "print(f\"\\nüìä Top 10 Similar Presets:\")\n",
    "display_cols = ['Rank', 'Similarity_Score', 'Name', 'Game', 'CON', 'FL', 'Brightness_Index']\n",
    "print(similar[display_cols].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART IV: CREATIVE CONTEXT\n",
    "\n",
    "## 11. Composers and Styles\n",
    "\n",
    "**Loading composer information from preprocessed data** (scraped in `Data_Extraction.ipynb` from Wikipedia and other sources).\n",
    "\n",
    "This enriches our dataset with creative context: **who made these sounds and where they came from**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.1 The Composers Behind the Sounds: Legends of the YM2612 Era\n",
    "\n",
    "**Why Composers Matter:**\n",
    "Each composer brought their unique style, technical approach, and creative vision to the YM2612. By analyzing their presets, we can discover their \"sonic signatures\"‚Äîthe parameter choices that made their music instantly recognizable.\n",
    "\n",
    "**Yuzo Koshiro: The Electronic Music Pioneer**\n",
    "Born in 1967, Yuzo Koshiro is perhaps the most famous video game composer of the 16-bit era. His work on **Streets of Rage** (Bare Knuckle in Japan) revolutionized video game music by blending FM synthesis with electronic dance music. Koshiro was inspired by early house and techno‚Äîhe would listen to tracks from Chicago and Detroit, then recreate those sounds using the YM2612's limited resources.\n",
    "\n",
    "**Fun Fact**: Koshiro programmed the Streets of Rage soundtrack using assembly language directly on the Genesis hardware, giving him unprecedented control over the chip. This is why Streets of Rage sounds so different from other Genesis games‚ÄîKoshiro was pushing the hardware in ways that higher-level tools couldn't achieve.\n",
    "\n",
    "**Masato Nakamura: From J-Pop to Video Games**\n",
    "Masato Nakamura is a member of the Japanese pop duo **Dreams Come True**, one of Japan's most successful bands. When Sega approached him to compose for **Sonic the Hedgehog**, he brought a pop sensibility that was unusual for video games at the time. The main theme, \"Green Hill Zone,\" became one of the most recognizable melodies in gaming history.\n",
    "\n",
    "**The Challenge**: Nakamura had to adapt his pop songwriting style to the YM2612's limitations. The result? Melodies that were catchy, memorable, and perfectly suited for gameplay‚Äîmusic that players would hear hundreds of times without getting tired of it.\n",
    "\n",
    "**Hiroshi Kawaguchi: The Sega Veteran**\n",
    "Hiroshi Kawaguchi worked at Sega for decades, composing for games like **Golden Axe**, **OutRun**, and **After Burner**. His style emphasized strong melodies and clear arrangements‚Äîperfect for arcade games where players needed to hear important audio cues over the noise of an arcade.\n",
    "\n",
    "**Technical Mastery**: Kawaguchi's presets often show careful attention to operator balance and envelope shaping. He understood that in a busy arcade environment, sounds needed to cut through clearly‚Äîthis is reflected in his parameter choices.\n",
    "\n",
    "**Norio Hanzawa: The Treasure Sound Designer**\n",
    "Norio Hanzawa worked at Treasure, a studio known for pushing hardware to its limits. His work on **Gunstar Heroes** showcases complex, layered FM sounds that create rich textures despite the chip's limitations. Hanzawa's approach was more experimental‚Äîhe wasn't afraid to use unusual algorithm combinations or push feedback to create unique timbres.\n",
    "\n",
    "**Why This Analysis Matters:**\n",
    "By comparing presets from different composers, we can see how:\n",
    "- **Technical constraints** shaped creative choices\n",
    "- **Personal style** emerged despite working with the same hardware\n",
    "- **Regional differences** (Japanese vs. American composers) influenced sound design\n",
    "- **Game genres** required different sonic approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGMrips composer data\n",
    "print(f\"   Unique games: {df['Game'].nunique()}\")\n",
    "print(f\"   Unique composers: {df['Composer'].nunique()}\")\n",
    "    \n",
    "# Show top composers\n",
    "print(f\"\\nüìä Top 10 composers by game count:\")\n",
    "composer_game_counts = df.groupby('Composer')['Game'].nunique().sort_values(ascending=False).head(10)\n",
    "for composer, count in composer_game_counts.items():\n",
    "    print(f\"   {composer}: {count} games\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load composer info\n",
    "# Show nationality distribution\n",
    "if 'Nationality' in df.columns:\n",
    "    print(f\"\\nüåç Nationality distribution:\")\n",
    "    print(df['Nationality'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# üéµ Top 10 composers by preset count\n",
    "# CON/FL as MODE; Brightness/Complexity as MEAN¬±STD\n",
    "# -------------------------------\n",
    "\n",
    "def mode_series(s: pd.Series):\n",
    "    \"\"\"Mode with tie-break to smallest value.\"\"\"\n",
    "    s = s.dropna()\n",
    "    if len(s) == 0:\n",
    "        return np.nan\n",
    "    vc = s.value_counts()\n",
    "    top = vc.iloc[0]\n",
    "    modes = vc[vc == top].index.tolist()\n",
    "    return min(modes)\n",
    "\n",
    "df_c = df[df['Composer'].notna()].copy()\n",
    "\n",
    "composer_stats = (\n",
    "    df_c.groupby('Composer')\n",
    "        .agg(\n",
    "            CON_Mode=('CON', mode_series),\n",
    "            FL_Mode=('FL', mode_series),\n",
    "\n",
    "            Brightness_Mean=('Brightness_Index', 'mean'),\n",
    "            Brightness_Std=('Brightness_Index', 'std'),\n",
    "            Complexity_Mean=('Complexity_Score', 'mean'),\n",
    "            Complexity_Std=('Complexity_Score', 'std'),\n",
    "\n",
    "            Preset_Count=('Filename', 'count'),\n",
    "            Nationality=('Nationality', 'first'),\n",
    "        )\n",
    ")\n",
    "\n",
    "# Round for display\n",
    "for c in ['CON_Mode','FL_Mode','Brightness_Mean','Brightness_Std','Complexity_Mean','Complexity_Std']:\n",
    "    if c in composer_stats.columns:\n",
    "        composer_stats[c] = composer_stats[c].round(2)\n",
    "\n",
    "print(\"üéµ Composer Statistics (Top by Preset_Count):\")\n",
    "print(composer_stats.sort_values('Preset_Count', ascending=False).head(20))\n",
    "\n",
    "# Select top 10 composers by preset count\n",
    "plot_stats = composer_stats.sort_values('Preset_Count', ascending=False).head(10)\n",
    "# Sort ascending for barh readability\n",
    "plot_stats = plot_stats.sort_values('Preset_Count', ascending=True)\n",
    "composers = plot_stats.index.tolist()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "\n",
    "# 1) CON mode\n",
    "axes[0, 0].barh(composers, plot_stats['CON_Mode'].values,\n",
    "                color=KASSER_COLORS['primary'], edgecolor='white', linewidth=1)\n",
    "axes[0, 0].set_title('Mode Algorithm (CON) ‚Äî Top 10 Composers', color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[0, 0].set_xlabel('CON Mode (0‚Äì7)', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[0, 0].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[0, 0].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[0, 0].spines['bottom'].set_color(KASSER_COLORS['primary'])\n",
    "axes[0, 0].spines['left'].set_color(KASSER_COLORS['primary'])\n",
    "axes[0, 0].spines['top'].set_visible(False)\n",
    "axes[0, 0].spines['right'].set_visible(False)\n",
    "\n",
    "# 2) FL mode\n",
    "axes[0, 1].barh(composers, plot_stats['FL_Mode'].values,\n",
    "                color=KASSER_COLORS['secondary'], edgecolor='white', linewidth=1)\n",
    "axes[0, 1].set_title('Mode Feedback (FL) ‚Äî Top 10 Composers', color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[0, 1].set_xlabel('FL Mode (0‚Äì7)', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[0, 1].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[0, 1].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[0, 1].spines['bottom'].set_color(KASSER_COLORS['secondary'])\n",
    "axes[0, 1].spines['left'].set_color(KASSER_COLORS['secondary'])\n",
    "axes[0, 1].spines['top'].set_visible(False)\n",
    "axes[0, 1].spines['right'].set_visible(False)\n",
    "\n",
    "# 3) Brightness mean ¬± std\n",
    "axes[1, 0].barh(composers, plot_stats['Brightness_Mean'].values,\n",
    "                xerr=plot_stats['Brightness_Std'].fillna(0).values,\n",
    "                color=KASSER_COLORS['tertiary'], edgecolor='white', linewidth=1)\n",
    "axes[1, 0].set_title('Brightness Index (Mean ¬± Std) ‚Äî Top 10 Composers', color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[1, 0].set_xlabel('Brightness Index (0‚Äì1)', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[1, 0].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[1, 0].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[1, 0].spines['bottom'].set_color(KASSER_COLORS['tertiary'])\n",
    "axes[1, 0].spines['left'].set_color(KASSER_COLORS['tertiary'])\n",
    "axes[1, 0].spines['top'].set_visible(False)\n",
    "axes[1, 0].spines['right'].set_visible(False)\n",
    "\n",
    "# 4) Complexity mean ¬± std\n",
    "axes[1, 1].barh(composers, plot_stats['Complexity_Mean'].values,\n",
    "                xerr=plot_stats['Complexity_Std'].fillna(0).values,\n",
    "                color=KASSER_COLORS['accent'], edgecolor='white', linewidth=1)\n",
    "axes[1, 1].set_title('Complexity Score (Mean ¬± Std) ‚Äî Top 10 Composers', color=KASSER_COLORS['text'], fontsize=12, fontweight='bold')\n",
    "axes[1, 1].set_xlabel('Complexity Score (0‚Äì1)', color=KASSER_COLORS['text'], fontweight='bold')\n",
    "axes[1, 1].set_facecolor(KASSER_COLORS['background'])\n",
    "axes[1, 1].tick_params(colors=KASSER_COLORS['text'])\n",
    "axes[1, 1].spines['bottom'].set_color(KASSER_COLORS['accent'])\n",
    "axes[1, 1].spines['left'].set_color(KASSER_COLORS['accent'])\n",
    "axes[1, 1].spines['top'].set_visible(False)\n",
    "axes[1, 1].spines['right'].set_visible(False)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è Mode Algorithm (CON) ‚Äî Top 10 Composers\n",
    "\n",
    "This chart shows a striking convergence among the most prolific YM2612 composers: **Algorithm 4** clearly dominates as the modal choice for almost everyone. This reinforces its role as the practical ‚Äúsweet spot‚Äù of Genesis FM synthesis‚Äîan algorithm that effectively behaves like two FM voices summed together, offering both richness and control. Composers such as **Yuzo Koshiro**, **Masato Nakamura**, and **Nobuo Uematsu** all gravitate toward this topology, despite their very different musical styles, which suggests that Algorithm 4 was less a stylistic choice and more a *structural workhorse*. The main exception is **Naoki Kodaka**, whose lower modal value hints at a more idiosyncratic routing strategy, consistent with his darker, more experimental sound worlds. Overall, the chart illustrates that even highly individual composers converged on the same FM topology when working under the constraints of the YM2612 üéπ.\n",
    "\n",
    "## üîÅ Mode Feedback (FL) ‚Äî Top 10 Composers\n",
    "\n",
    "The feedback chart is almost shockingly uniform: **FL = 7** is the modal value for virtually every composer shown. This confirms that maximum feedback was not a special effect, but a **default compositional tool** on the Genesis. High feedback turns Operator 1 into a dense harmonic or noise-rich source, adding aggression, brightness, and presence with minimal programming overhead. For composers like **Koshiro** or **Yamashita**, whose music needed to cut through fast-paced action and heavy percussion, this choice makes perfect sense. The lack of variation here underscores a key insight: feedback on the YM2612 behaves more like a *binary aesthetic switch* than a subtle continuous control‚Äîeither fully embraced for impact, or avoided entirely.\n",
    "\n",
    "## üåà Brightness Index (Mean ¬± Std) ‚Äî Top 10 Composers\n",
    "\n",
    "Brightness Index values cluster tightly in the **mid-to-high range (‚âà 0.55‚Äì0.7)** across all top composers, revealing a shared perceptual target rather than wildly different tonal philosophies. Even composers with very different musical identities‚Äîsuch as **Masato Nakamura‚Äôs melodic pop sensibility** versus **Koshiro‚Äôs club-inspired aggression**‚Äîarrive at similar brightness averages. This reflects the realities of Genesis playback: small TV speakers, limited dynamic range, and dense mixes strongly favor brighter FM patches. The relatively modest standard deviations suggest that brightness was not wildly exploratory, but carefully managed, reinforcing the idea of a widely understood ‚Äúsafe brightness zone‚Äù that maximized clarity without tipping into harshness ‚ú®.\n",
    "\n",
    "## üß© Complexity Score (Mean ¬± Std) ‚Äî Top 10 Composers\n",
    "\n",
    "The Complexity Score chart shows more variation than brightness, but still a clear tendency toward **upper-mid complexity values**. Most composers cluster around **0.65‚Äì0.8**, indicating a preference for patches with multiple active operators and meaningful internal modulation, yet stopping short of maximal complexity. This balance reflects a deep practical understanding of FM synthesis: richer operator interactions create expressive, evolving timbres, but excessive complexity can reduce predictability and mix clarity. Slight differences between composers are revealing‚Äîsome, like **Nobuo Uematsu**, lean a bit higher toward lush internal structure, while others favor slightly simpler designs‚Äîyet everyone remains within a narrow, musically effective band. The takeaway is clear: Genesis composers consistently sought **controlled richness**, not chaos, in their FM designs üéÆ.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11.2 Regional Patterns: The Cultural DNA of Sound\n",
    "\n",
    "**Why Nationality Matters:**\n",
    "Different regions had different musical traditions, technical approaches, and creative philosophies. By analyzing presets by composer nationality, we can discover:\n",
    "\n",
    "**Japanese Composers: The Technical Masters**\n",
    "Japanese game music composers often had backgrounds in both classical music and electronic music. This dual expertise shows in their presets:\n",
    "- **Precision in parameter tuning**: Japanese composers were meticulous about operator balance\n",
    "- **Melodic sophistication**: Complex melodies requiring careful voice leading\n",
    "- **Technical innovation**: Willingness to experiment with unusual algorithm combinations\n",
    "\n",
    "**American Composers: The Genre Blenders**\n",
    "American composers often came from rock, jazz, or film scoring backgrounds. Their presets reflect this:\n",
    "- **Rhythmic emphasis**: Strong use of percussive elements\n",
    "- **Genre fusion**: Blending FM synthesis with sampled elements\n",
    "- **Practical efficiency**: Focus on sounds that work well in gameplay contexts\n",
    "\n",
    "**European Composers: The Experimentalists**\n",
    "European composers (especially from the UK) often had backgrounds in electronic music and chiptune scenes:\n",
    "- **Experimental approaches**: Unusual parameter combinations\n",
    "- **Atmospheric focus**: Emphasis on pads and evolving textures\n",
    "- **Technical creativity**: Finding new ways to use familiar tools\n",
    "\n",
    "**The Data Science Perspective:**\n",
    "These regional differences create **natural clusters** in our data. Machine learning can identify these patterns even when we don't explicitly label them. This is the power of **unsupervised learning**‚Äîdiscovering structure we didn't know existed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mode_series(s: pd.Series):\n",
    "    \"\"\"Return the mode (most frequent) for a Series; ties -> smallest value.\"\"\"\n",
    "    s = s.dropna()\n",
    "    if len(s) == 0:\n",
    "        return np.nan\n",
    "    vc = s.value_counts()\n",
    "    top = vc.iloc[0]\n",
    "    modes = vc[vc == top].index.tolist()\n",
    "    return min(modes)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# üåç Analyze by nationality (using df_embed)\n",
    "# CON/FL = MODE, Brightness/Complexity = MEAN\n",
    "# -------------------------------\n",
    "required_cols_stats = ['Nationality', 'CON', 'FL', 'Brightness_Index', 'Complexity_Score', 'Filename']\n",
    "missing = [c for c in required_cols_stats if c not in df_embed.columns]\n",
    "\n",
    "if missing:\n",
    "    print(f\"‚ö†Ô∏è Missing columns for nationality stats in df_embed: {missing}\")\n",
    "else:\n",
    "    nationality_stats = (\n",
    "        df_embed[df_embed['Nationality'].notna()]\n",
    "        .groupby('Nationality', dropna=True)\n",
    "        .agg(\n",
    "            Mode_Algorithm=('CON', mode_series),\n",
    "            Mode_Feedback=('FL', mode_series),\n",
    "            Avg_Brightness=('Brightness_Index', 'mean'),\n",
    "            Avg_Complexity=('Complexity_Score', 'mean'),\n",
    "            Preset_Count=('Filename', 'count'),\n",
    "        )\n",
    "        .round(2)\n",
    "        .sort_values('Preset_Count', ascending=False)\n",
    "    )\n",
    "\n",
    "    print(\"üåç Regional Statistics (CON/FL as mode):\")\n",
    "    print(nationality_stats)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# üìç Visualize on embedding (using df_embed)\n",
    "# -------------------------------\n",
    "needed_embed_cols = ['embed_x', 'embed_y', 'Nationality']\n",
    "missing_plot = [c for c in needed_embed_cols if c not in df_embed.columns]\n",
    "\n",
    "if missing_plot:\n",
    "    print(f\"‚ö†Ô∏è Missing columns for embedding plot in df_embed: {missing_plot}\")\n",
    "else:\n",
    "    df_plot = df_embed[df_embed['Nationality'].notna()].copy()\n",
    "\n",
    "    fig = px.scatter(\n",
    "        df_plot,\n",
    "        x='embed_x',\n",
    "        y='embed_y',\n",
    "        color='Nationality',\n",
    "        title=f'Presets Colored by Composer Nationality - {method}',\n",
    "        hover_data=[c for c in ['Name', 'Game', 'Composer'] if c in df_plot.columns],\n",
    "        width=1000,\n",
    "        height=700\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=KASSER_COLORS['background'],\n",
    "        paper_bgcolor=KASSER_COLORS['background'],\n",
    "        font_color=KASSER_COLORS['text'],\n",
    "        title_font_size=16,\n",
    "        title_font_color=KASSER_COLORS['text'],\n",
    "        font_family='sans-serif'\n",
    "    )\n",
    "    fig.update_traces(marker=dict(size=3, opacity=0.6))\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Regional Statistics\n",
    "\n",
    "The statistical table reinforces this visual impression of convergence. Across all major regions, the **modal algorithm is Algorithm 4**, and the **modal feedback is FL = 7**, confirming that these were not stylistic outliers but universal defaults. Brightness averages are nearly identical for Japan, USA, and Unknown (‚âà 0.62), with the UK slightly higher (0.66), while complexity scores remain tightly clustered around ~0.70. The main difference between regions is not *how* sounds were designed, but *how many* presets are represented‚ÄîJapan overwhelmingly dominates the dataset in sheer volume. Overall, this suggests that YM2612 sound design evolved into a **shared international language**, where optimal FM strategies emerged naturally and were reused everywhere, independent of geography üéõÔ∏è‚ú®.\n",
    "\n",
    "\n",
    "## üåç Embedding Space by Nationality\n",
    "\n",
    "The embedding visualization shows a **strong overlap between nationalities**, with Japanese, USA, UK, and Unknown presets largely occupying the same dense regions of the latent space. Rather than forming clearly separated clusters, presets from different regions are deeply interwoven, suggesting that **timbre design on the YM2612 converged globally toward similar solutions**, regardless of cultural background. This makes sense in historical context: composers across regions were working with the same hardware constraints, similar reference sounds, and often shared genre goals (action, platformers, racing). The lack of strong geographic separation implies that *technology and medium* had a stronger shaping force on sound design than nationality itself üåêüéÆ.\n",
    "\n",
    "## üá¨üáß A Distinct UK Sonic Signature?\n",
    "\n",
    "On closer inspection of the embedding, the **UK presets do show a subtle but meaningful deviation**, tending to cluster toward the **lower-left region** of the latent space rather than fully overlapping with the main mass dominated by Japanese presets. While the separation is not absolute, this displacement suggests that UK composers may indeed have explored a **slightly different sonic universe** on the YM2612. Historically, this aligns well with context: many UK developers came from a home-computer background (ZX Spectrum, Amiga, Atari ST), where darker, rougher, and more noise-oriented timbres were common. When transitioning to the Mega Drive, these aesthetics likely carried over, resulting in patches that are perceptually distinct despite using the same algorithms and feedback settings. In other words, the UK did not reject the ‚Äústandard‚Äù FM toolbox‚Äîbut they **bent it toward a grittier, moodier space**, carving out a recognizable sonic fingerprint within the shared Genesis sound world üéÆüåë."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 12. GEMS: The American Driver\n",
    "\n",
    "**GEMS** (Genesis Editor for Music and Sound) was Sega of America's music tool - used in **200+ games**.\n",
    "\n",
    "<div align=\"center\">\n",
    "\n",
    "![GEMS Interface](images/gems-interface.png)\n",
    "\n",
    "*GEMS - The tool that shaped American Genesis game music.*  \n",
    "*Image: Sega Retro*\n",
    "\n",
    "</div>\n",
    "\n",
    "| Aspect | Impact |\n",
    "|--------|--------|\n",
    "| **Template presets** | Same sounds in multiple games |\n",
    "| **Regional divide** | USA: GEMS vs Japan: Custom tools |\n",
    "| **Controversy** | \"Generic\" sound vs accessibility |\n",
    "\n",
    "üîç **Data Science Question**: Can we identify GEMS clusters in the embedding space?\n",
    "\n",
    "üìö **Learn more**: [Sega Retro - GEMS](https://www.segaretro.org/GEMS) | YouTube: \"How to Make Sega Genesis Music (1994)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.1 GEMS Statistics from Dataset\n",
    "\n",
    "The `Uses_GEMS` column was already computed during data extraction (in `01-Data_Extraction.ipynb`) by matching game names against the official GEMS games list from Sega Retro. Let's explore the statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GEMS Statistics (Uses_GEMS column already exists in df from data extraction)\n",
    "# ============================================================================\n",
    "\n",
    "def mode_series(s: pd.Series):\n",
    "    \"\"\"Return the mode (most frequent) for a Series; ties -> smallest value.\"\"\"\n",
    "    s = s.dropna()\n",
    "    if len(s) == 0:\n",
    "        return float('nan')\n",
    "    vc = s.value_counts()\n",
    "    top = vc.iloc[0]\n",
    "    modes = vc[vc == top].index.tolist()\n",
    "    return min(modes)\n",
    "\n",
    "if 'Uses_GEMS' not in df.columns:\n",
    "    print(\"‚ö†Ô∏è 'Uses_GEMS' column not found in df. Run 01-Data_Extraction.ipynb first.\")\n",
    "else:\n",
    "    # Ensure boolean type\n",
    "    df['Uses_GEMS'] = df['Uses_GEMS'].fillna(False).astype(bool)\n",
    "\n",
    "    # Basic statistics\n",
    "    total_presets = len(df)\n",
    "    gems_presets = int(df['Uses_GEMS'].sum())\n",
    "    total_games = df['Game'].nunique(dropna=True) if 'Game' in df.columns else 0\n",
    "    gems_games = df.loc[df['Uses_GEMS'], 'Game'].nunique(dropna=True) if 'Game' in df.columns else 0\n",
    "\n",
    "    print(\"üìä GEMS Statistics:\")\n",
    "    print(f\"   Total presets: {total_presets:,}\")\n",
    "    print(f\"   Presets from GEMS games: {gems_presets:,} ({(gems_presets/total_presets*100):.1f}%)\" if total_presets else\n",
    "          \"   Presets from GEMS games: 0 (0.0%)\")\n",
    "    print(f\"   Total unique games: {total_games:,}\")\n",
    "    print(f\"   Games using GEMS: {gems_games:,}\")\n",
    "\n",
    "    # Top GEMS games by preset count\n",
    "    if gems_games > 0:\n",
    "        print(\"\\nüéÆ Top GEMS games in dataset (by preset count):\")\n",
    "        top_gems = (df[df['Uses_GEMS'] & df['Game'].notna()]\n",
    "                    .groupby('Game').size()\n",
    "                    .sort_values(ascending=False))\n",
    "        for game, cnt in top_gems.head(15).items():\n",
    "            print(f\"   ‚Ä¢ {game}: {cnt} presets\")\n",
    "        if len(top_gems) > 15:\n",
    "            print(f\"   ... and {len(top_gems) - 15} more\")\n",
    "\n",
    "    # Average presets per game comparison\n",
    "    gems_sizes = df[df['Uses_GEMS'] & df['Game'].notna()].groupby('Game').size()\n",
    "    nongems_sizes = df[~df['Uses_GEMS'] & df['Game'].notna()].groupby('Game').size()\n",
    "    gems_avg = gems_sizes.mean() if len(gems_sizes) else float('nan')\n",
    "    nongems_avg = nongems_sizes.mean() if len(nongems_sizes) else float('nan')\n",
    "\n",
    "    print(\"\\nüìà Presets per Game:\")\n",
    "    print(f\"   GEMS games: {gems_avg:.1f} avg presets/game\" if pd.notna(gems_avg) else \"   GEMS games: n/a\")\n",
    "    print(f\"   Non-GEMS games: {nongems_avg:.1f} avg presets/game\" if pd.notna(nongems_avg) else \"   Non-GEMS games: n/a\")\n",
    "\n",
    "    # Parameter comparison (CON/FL as MODE; Brightness/Complexity as MEAN)\n",
    "    print(\"\\nüéπ Parameter Comparison (GEMS vs Non-GEMS):\")\n",
    "    gems_df = df[df['Uses_GEMS']]\n",
    "    nongems_df = df[~df['Uses_GEMS']]\n",
    "\n",
    "    for col, label in [('CON', 'Algorithm (mode)'), ('FL', 'Feedback (mode)'),\n",
    "                       ('Brightness_Index', 'Brightness (avg)'), ('Complexity_Score', 'Complexity (avg)')]:\n",
    "        if col in df.columns:\n",
    "            if col in ['CON', 'FL']:\n",
    "                g_val = mode_series(gems_df[col]) if len(gems_df) else float('nan')\n",
    "                n_val = mode_series(nongems_df[col]) if len(nongems_df) else float('nan')\n",
    "                print(f\"   {label}: GEMS={g_val}, Non-GEMS={n_val}\")\n",
    "            else:\n",
    "                g_val = gems_df[col].mean() if len(gems_df) else float('nan')\n",
    "                n_val = nongems_df[col].mean() if len(nongems_df) else float('nan')\n",
    "                print(f\"   {label}: GEMS={g_val:.3f}, Non-GEMS={n_val:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéÆ GEMS Usage and Sonic Characteristics\n",
    "\n",
    "Although **GEMS-powered games represent only a small fraction of the dataset**‚Äîjust **7.3% of all presets** and **43 out of 547 games**‚Äîthey still contribute a substantial body of material, with over **1,600 presets** available for analysis. Titles such as *Nightmare Circus*, *Marsupilami*, *Shadowrun*, and *Chakan* stand out with unusually large preset counts, reflecting the fact that GEMS encouraged more systematic and reusable sound design compared to many hand-crafted FM workflows. Interestingly, the **average number of presets per game is slightly lower for GEMS titles** than for non-GEMS games, suggesting that GEMS prioritized *structured consistency* over sheer preset volume.\n",
    "\n",
    "From a synthesis perspective, the contrast is revealing. **GEMS games overwhelmingly favor Algorithm 2 as their modal choice**, while the broader Genesis ecosystem converges on **Algorithm 4**, reinforcing the idea that GEMS imposed (or at least encouraged) a different internal FM architecture. Even more striking is the feedback behavior: **GEMS presets default to FL = 0**, whereas non-GEMS presets almost universally push feedback to the maximum (FL = 7). This aligns perfectly with GEMS‚Äô historical role as a higher-level music engine‚Äîdesigned for stability, predictability, and portability‚Äîrather than raw, aggressive timbral experimentation. Brightness and complexity averages are only slightly lower in GEMS presets, indicating that **the sonic difference is not about dullness or simplicity**, but about *control*: GEMS trades extreme feedback-driven character for cleaner, more manageable FM tones that could be reliably deployed across large, multi-track game soundtracks üéõÔ∏è‚ú®.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12.2 GEMS in the Embedding Space\n",
    "\n",
    "Let's visualize where GEMS presets appear in our 2D embedding to see if they form distinct clusters or are spread throughout the space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize GEMS vs Non-GEMS in embedding space\n",
    "# ==============================================\n",
    "\n",
    "if 'embed_x' not in df_embed.columns or 'embed_y' not in df_embed.columns:\n",
    "    print(\"‚ö†Ô∏è Embedding coordinates not found. Run the embedding section first.\")\n",
    "elif 'Uses_GEMS' not in df_embed.columns:\n",
    "    print(\"‚ö†Ô∏è 'Uses_GEMS' column not found.\")\n",
    "else:\n",
    "    # Prepare data\n",
    "    df_embed['Uses_GEMS'] = df_embed['Uses_GEMS'].fillna(False).astype(bool)\n",
    "    non_gems = df_embed[~df_embed['Uses_GEMS']]\n",
    "    gems = df_embed[df_embed['Uses_GEMS']]\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Non-GEMS presets (background)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=non_gems['embed_x'], y=non_gems['embed_y'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=3, color=KASSER_COLORS['primary'], opacity=0.4),\n",
    "        name='Non-GEMS Games',\n",
    "        text=non_gems['Game'], hoverinfo='text'\n",
    "    ))\n",
    "    \n",
    "    # GEMS presets (highlighted)\n",
    "    fig.add_trace(go.Scatter(\n",
    "        x=gems['embed_x'], y=gems['embed_y'],\n",
    "        mode='markers',\n",
    "        marker=dict(size=5, color=KASSER_COLORS['secondary'], opacity=0.8,\n",
    "                    line=dict(width=1, color='white')),\n",
    "        name='GEMS Games',\n",
    "        text=gems['Game'], hoverinfo='text'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        title=f'GEMS vs Non-GEMS Presets in Embedding Space ({method})',\n",
    "        plot_bgcolor=KASSER_COLORS['background'],\n",
    "        paper_bgcolor=KASSER_COLORS['background'],\n",
    "        font_color=KASSER_COLORS['text'],\n",
    "        width=1200, height=800,\n",
    "        legend=dict(bgcolor='rgba(0,0,0,0.8)', bordercolor=KASSER_COLORS['primary'])\n",
    "    )\n",
    "    fig.show()\n",
    "    \n",
    "    # Summary\n",
    "    print(f\"\\nüìä GEMS in Embedding: {len(gems):,} ({len(gems)/len(df_embed)*100:.1f}%) | Non-GEMS: {len(non_gems):,}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéõÔ∏è GEMS vs Non-GEMS in Embedding Space\n",
    "\n",
    "This embedding makes visually explicit what the statistics already suggested: **GEMS and non-GEMS presets largely inhabit the same sonic territory**, with no hard separation between the two groups. The GEMS presets (highlighted) are deeply interwoven with the broader cloud of non-GEMS sounds, indicating that GEMS was not producing an alien or radically different timbral palette. Instead, it operated firmly *within* the established YM2612 sound space. That said, GEMS points appear slightly more concentrated toward the central mass, while non-GEMS presets spread a bit further toward the periphery, hinting at greater experimentation and extremity outside the GEMS workflow.\n",
    "\n",
    "This pattern aligns perfectly with GEMS‚Äô historical role as a **production-oriented abstraction layer** rather than a creative constraint. By favoring stable algorithms, low feedback, and predictable behavior, GEMS effectively *compressed the expressive space*, reducing outliers while still covering the core timbres needed for game music. Non-GEMS composers, working closer to the metal, were more willing to push the chip into edge cases‚Äîhigh feedback noise, unstable modulations, or extreme routings‚Äîwhich manifest here as broader dispersion. In short, the image shows that **GEMS standardized FM sound design without sterilizing it**, anchoring itself at the center of the Genesis sonic universe rather than orbiting outside it üéÆ‚ú®.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 13. Interactive Exploration\n",
    "\n",
    "Now let's explore specific games and presets in the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.1 Find Your Favorite Game\n",
    "\n",
    "**üëâ MODIFY THIS CODE:**\n",
    "\n",
    "Search for any game in the dataset. Change `GAME_SEARCH` to find different games!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üéÆ FIND YOUR FAVORITE GAME + highlight on embedding map (uses df_embed)\n",
    "# =====================================================================\n",
    "GAME_SEARCH = \"Chakan\"  # Try: \"Streets\", \"Golden\", \"Phantasy\", \"Comix\"\n",
    "\n",
    "def mode_series(s: pd.Series):\n",
    "    \"\"\"Return the mode (most frequent) for a Series; ties -> smallest value.\"\"\"\n",
    "    s = s.dropna()\n",
    "    if len(s) == 0:\n",
    "        return np.nan\n",
    "    vc = s.value_counts()\n",
    "    top = vc.iloc[0]\n",
    "    modes = vc[vc == top].index.tolist()\n",
    "    return min(modes)\n",
    "\n",
    "# --- Search for matching games\n",
    "matching_games = df[df['Game'].str.contains(GAME_SEARCH, case=False, na=False)]['Game'].unique()\n",
    "\n",
    "print(f\"üéÆ Games found matching '{GAME_SEARCH}':\")\n",
    "for game in sorted(matching_games)[:20]:\n",
    "    preset_count = (df['Game'] == game).sum()\n",
    "    print(f\"   ‚Ä¢ {game}: {preset_count} presets\")\n",
    "if len(matching_games) > 20:\n",
    "    print(f\"   ... and {len(matching_games) - 20} more\")\n",
    "\n",
    "# --- Stats for first match\n",
    "if len(matching_games) > 0:\n",
    "    first_game = sorted(matching_games)[0]\n",
    "    game_df = df[df['Game'] == first_game]\n",
    "\n",
    "    print(f\"\\nüìä Statistics for '{first_game}':\")\n",
    "    print(f\"   Total presets: {len(game_df)}\")\n",
    "    print(f\"   Algorithms used: {sorted(game_df['CON'].dropna().unique())}\")\n",
    "    if 'CON' in game_df.columns:\n",
    "        print(f\"   Mode algorithm (CON): {mode_series(game_df['CON'])}\")\n",
    "    if 'FL' in game_df.columns:\n",
    "        print(f\"   Mode feedback (FL): {mode_series(game_df['FL'])}\")\n",
    "    if 'Brightness_Index' in game_df.columns:\n",
    "        print(f\"   Average brightness: {game_df['Brightness_Index'].mean():.3f}\")\n",
    "    if 'Complexity_Score' in game_df.columns:\n",
    "        print(f\"   Average complexity: {game_df['Complexity_Score'].mean():.3f}\")\n",
    "\n",
    "    # --- Embedding map: full + highlight selected game's presets (df_embed)\n",
    "    needed = ['embed_x', 'embed_y', 'Game']\n",
    "    missing = [c for c in needed if c not in df_embed.columns]\n",
    "    if missing:\n",
    "        print(f\"‚ö†Ô∏è df_embed missing columns for embedding plot: {missing}\")\n",
    "    else:\n",
    "        plot_df = df_embed.copy()\n",
    "        plot_df['Is_Selected_Game'] = (plot_df['Game'] == first_game)\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Background: all other presets\n",
    "        bg = plot_df[~plot_df['Is_Selected_Game']]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=bg['embed_x'],\n",
    "            y=bg['embed_y'],\n",
    "            mode='markers',\n",
    "            marker=dict(size=3, color=KASSER_COLORS['primary'], opacity=0.25),\n",
    "            name='All other presets',\n",
    "            hoverinfo='skip'\n",
    "        ))\n",
    "\n",
    "        # Highlight: selected game presets\n",
    "        hi = plot_df[plot_df['Is_Selected_Game']]\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=hi['embed_x'],\n",
    "            y=hi['embed_y'],\n",
    "            mode='markers',\n",
    "            marker=dict(size=6, color=KASSER_COLORS['secondary'], opacity=0.95,\n",
    "                        line=dict(width=1, color='white')),\n",
    "            name=f\"{first_game} presets\",\n",
    "            text=hi['Game'],\n",
    "            hoverinfo='text'\n",
    "        ))\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Embedding Map ‚Äî Highlighted presets for '{first_game}' ({method})\",\n",
    "            plot_bgcolor=KASSER_COLORS['background'],\n",
    "            paper_bgcolor=KASSER_COLORS['background'],\n",
    "            font_color=KASSER_COLORS['text'],\n",
    "            title_font_color=KASSER_COLORS['text'],\n",
    "            font_family='sans-serif',\n",
    "            width=1100,\n",
    "            height=800,\n",
    "            showlegend=True,\n",
    "            legend=dict(\n",
    "                bgcolor='rgba(0,0,0,0.8)',\n",
    "                bordercolor=KASSER_COLORS['primary'],\n",
    "                borderwidth=1\n",
    "            )\n",
    "        )\n",
    "\n",
    "        fig.show()\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No matching games found.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.2 Compare Two Games\n",
    "\n",
    "**üëâ MODIFY THIS CODE:**\n",
    "\n",
    "Compare any two games side-by-side. Change `GAME_A` and `GAME_B` to explore different comparisons!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üÜö COMPARE TWO GAMES\n",
    "# ================================\n",
    "# üëâ MODIFY THIS: Choose two games to compare\n",
    "GAME_A = \"Sonic the Hedgehog\"\n",
    "GAME_B = \"Streets of Rage\"\n",
    "\n",
    "def mode_series(s: pd.Series):\n",
    "    \"\"\"Return the mode (most frequent) for a Series; ties -> smallest value.\"\"\"\n",
    "    s = s.dropna()\n",
    "    if len(s) == 0:\n",
    "        return np.nan\n",
    "    vc = s.value_counts()\n",
    "    top = vc.iloc[0]\n",
    "    modes = vc[vc == top].index.tolist()\n",
    "    return min(modes)\n",
    "\n",
    "# Get presets from both games (in df)\n",
    "game_a_df = df[df['Game'].str.contains(GAME_A, case=False, na=False)]\n",
    "game_b_df = df[df['Game'].str.contains(GAME_B, case=False, na=False)]\n",
    "\n",
    "print(f\"üÜö Comparison: {GAME_A} vs {GAME_B}\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if len(game_a_df) > 0 and len(game_b_df) > 0:\n",
    "    comparison_data = {\n",
    "        'Metric': ['Total Presets', 'Mode Algorithm (CON)', 'Mode Feedback (FL)',\n",
    "                   'Avg Brightness', 'Avg Complexity'],\n",
    "        GAME_A[:20]: [\n",
    "            len(game_a_df),\n",
    "            f\"{mode_series(game_a_df['CON'])}\",\n",
    "            f\"{mode_series(game_a_df['FL'])}\",\n",
    "            f\"{game_a_df['Brightness_Index'].mean():.3f}\" if 'Brightness_Index' in game_a_df.columns else 'N/A',\n",
    "            f\"{game_a_df['Complexity_Score'].mean():.3f}\" if 'Complexity_Score' in game_a_df.columns else 'N/A'\n",
    "        ],\n",
    "        GAME_B[:20]: [\n",
    "            len(game_b_df),\n",
    "            f\"{mode_series(game_b_df['CON'])}\",\n",
    "            f\"{mode_series(game_b_df['FL'])}\",\n",
    "            f\"{game_b_df['Brightness_Index'].mean():.3f}\" if 'Brightness_Index' in game_b_df.columns else 'N/A',\n",
    "            f\"{game_b_df['Complexity_Score'].mean():.3f}\" if 'Complexity_Score' in game_b_df.columns else 'N/A'\n",
    "        ]\n",
    "    }\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    print(comparison_df.to_string(index=False))\n",
    "\n",
    "    # -------------------------------\n",
    "    # Embedding plot using df_embed\n",
    "    # -------------------------------\n",
    "    needed = ['embed_x', 'embed_y', 'Game']\n",
    "    missing = [c for c in needed if c not in df_embed.columns]\n",
    "    if missing:\n",
    "        print(f\"\\n‚ö†Ô∏è df_embed missing columns for embedding plot: {missing}\")\n",
    "    else:\n",
    "        # Match games in df_embed using the same contains logic\n",
    "        emb_a = df_embed[df_embed['Game'].str.contains(GAME_A, case=False, na=False)].copy()\n",
    "        emb_b = df_embed[df_embed['Game'].str.contains(GAME_B, case=False, na=False)].copy()\n",
    "        emb_other = df_embed[~df_embed.index.isin(emb_a.index.union(emb_b.index))].copy()\n",
    "\n",
    "        fig = go.Figure()\n",
    "\n",
    "        # Background: all other presets\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=emb_other['embed_x'],\n",
    "            y=emb_other['embed_y'],\n",
    "            mode='markers',\n",
    "            marker=dict(size=3, color=KASSER_COLORS['primary'], opacity=0.18),\n",
    "            name='Other presets',\n",
    "            hoverinfo='skip'\n",
    "        ))\n",
    "\n",
    "        # Game A\n",
    "        if len(emb_a) > 0:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=emb_a['embed_x'],\n",
    "                y=emb_a['embed_y'],\n",
    "                mode='markers',\n",
    "                marker=dict(size=7, color=KASSER_COLORS['secondary'], opacity=0.95,\n",
    "                            line=dict(width=1, color='white')),\n",
    "                name=f\"{GAME_A} presets\",\n",
    "                text=emb_a['Game'],\n",
    "                hoverinfo='text'\n",
    "            ))\n",
    "        else:\n",
    "            print(f\"‚ÑπÔ∏è No df_embed points found for GAME_A='{GAME_A}'\")\n",
    "\n",
    "        # Game B\n",
    "        if len(emb_b) > 0:\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=emb_b['embed_x'],\n",
    "                y=emb_b['embed_y'],\n",
    "                mode='markers',\n",
    "                marker=dict(size=7, color=KASSER_COLORS['accent'], opacity=0.95,\n",
    "                            line=dict(width=1, color='white')),\n",
    "                name=f\"{GAME_B} presets\",\n",
    "                text=emb_b['Game'],\n",
    "                hoverinfo='text'\n",
    "            ))\n",
    "        else:\n",
    "            print(f\"‚ÑπÔ∏è No df_embed points found for GAME_B='{GAME_B}'\")\n",
    "\n",
    "        fig.update_layout(\n",
    "            title=f\"Embedding Map ‚Äî {GAME_A} vs {GAME_B} ({method})\",\n",
    "            plot_bgcolor=KASSER_COLORS['background'],\n",
    "            paper_bgcolor=KASSER_COLORS['background'],\n",
    "            font_color=KASSER_COLORS['text'],\n",
    "            title_font_color=KASSER_COLORS['text'],\n",
    "            font_family='sans-serif',\n",
    "            width=1100,\n",
    "            height=800,\n",
    "            showlegend=True,\n",
    "            legend=dict(\n",
    "                bgcolor='rgba(0,0,0,0.8)',\n",
    "                bordercolor=KASSER_COLORS['primary'],\n",
    "                borderwidth=1\n",
    "            )\n",
    "        )\n",
    "        fig.show()\n",
    "\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è No presets found for one or both games\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13.3 Find Similar Presets\n",
    "\n",
    "**üëâ MODIFY THIS CODE:**\n",
    "\n",
    "Find presets similar to any preset you want. Change `PRESET_NAME` to search for different sounds!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# üî¨ FIND SIMILAR PRESETS IN *THE SAME SPACE AS THE EMBEDDING MAP* (df_embed embed_x/embed_y)\n",
    "# ==========================================================================================\n",
    "PRESET_NAME = \"Instrument 0\"\n",
    "GAME_NAME   = \"Sonic\"\n",
    "NUM_SIMILAR = 10\n",
    "\n",
    "# Require both fields to be filled\n",
    "if not PRESET_NAME.strip() or not GAME_NAME.strip():\n",
    "    print(\"‚ö†Ô∏è Please fill BOTH PRESET_NAME and GAME_NAME before searching.\")\n",
    "else:\n",
    "    # 1) Find the query preset in df (your metadata table)\n",
    "    matching_presets = df[\n",
    "        df['Name'].astype(str).str.contains(PRESET_NAME, case=False, na=False) &\n",
    "        df['Game'].astype(str).str.contains(GAME_NAME, case=False, na=False)\n",
    "    ]\n",
    "\n",
    "    if len(matching_presets) == 0:\n",
    "        print(f\"‚ö†Ô∏è No presets found with preset='{PRESET_NAME}' AND game='{GAME_NAME}'.\")\n",
    "    else:\n",
    "        preset_idx = matching_presets.index[0]\n",
    "        preset = df.loc[preset_idx]\n",
    "\n",
    "        print(f\"üéπ Selected preset: '{preset['Name']}' from {preset['Game']}\")\n",
    "        if 'CON' in df.columns:\n",
    "            print(f\"   Algorithm (CON): {preset.get('CON', 'n/a')}\")\n",
    "        if 'FL' in df.columns:\n",
    "            print(f\"   Feedback (FL): {preset.get('FL', 'n/a')}\")\n",
    "        if 'Brightness_Index' in df.columns and pd.notna(preset.get('Brightness_Index', np.nan)):\n",
    "            print(f\"   Brightness (metric): {preset['Brightness_Index']:.3f}\")\n",
    "        if 'Complexity_Score' in df.columns and pd.notna(preset.get('Complexity_Score', np.nan)):\n",
    "            print(f\"   Complexity (metric): {preset['Complexity_Score']:.3f}\")\n",
    "\n",
    "        # 2) Validate df_embed columns\n",
    "        required_cols = ['embed_x', 'embed_y', 'Game', 'Name']\n",
    "        missing = [c for c in required_cols if c not in df_embed.columns]\n",
    "        if missing:\n",
    "            print(f\"\\n‚ö†Ô∏è df_embed missing required columns for embedding search/plot: {missing}\")\n",
    "        else:\n",
    "            # 3) Build a stable key to align df and df_embed (no iloc assumptions)\n",
    "            def _norm(s):\n",
    "                return str(s).strip().lower()\n",
    "\n",
    "            df_embed_local = df_embed.copy()\n",
    "            df_embed_local['preset_id'] = (\n",
    "                df_embed_local['Game'].map(_norm) + \"||\" + df_embed_local['Name'].map(_norm)\n",
    "            )\n",
    "\n",
    "            query_id = _norm(preset['Game']) + \"||\" + _norm(preset['Name'])\n",
    "\n",
    "            # Find query row(s) in df_embed\n",
    "            query_rows = df_embed_local.index[df_embed_local['preset_id'] == query_id].tolist()\n",
    "\n",
    "            if len(query_rows) == 0:\n",
    "                print(\"\\n‚ö†Ô∏è Could not locate the selected preset in df_embed by (Game, Name).\")\n",
    "                print(\"   Tip: ensure df_embed['Game','Name'] match df exactly (same spelling/casing), or add an explicit unique ID.\")\n",
    "            else:\n",
    "                # If duplicates exist, take the first (you can change this behavior)\n",
    "                query_row = query_rows[0]\n",
    "\n",
    "                # 4) Nearest neighbors IN EMBEDDING SPACE (embed_x/embed_y)\n",
    "                X = df_embed_local[['embed_x', 'embed_y']].astype(float).values\n",
    "                q = df_embed_local.loc[[query_row], ['embed_x', 'embed_y']].astype(float).values\n",
    "\n",
    "                # Euclidean in the 2D map space\n",
    "                nn2 = NearestNeighbors(n_neighbors=NUM_SIMILAR + 1, metric='euclidean')\n",
    "                nn2.fit(X)\n",
    "\n",
    "                distances, indices = nn2.kneighbors(q, n_neighbors=NUM_SIMILAR + 1)\n",
    "\n",
    "                # Exclude the query itself\n",
    "                similar_embed_indices = indices[0][1:]\n",
    "                similar_embed_distances = distances[0][1:]\n",
    "\n",
    "                similar_points = df_embed_local.iloc[list(similar_embed_indices)]\n",
    "                query_point = df_embed_local.iloc[[query_row]]\n",
    "\n",
    "                print(f\"\\nüîç Top {NUM_SIMILAR} most similar presets (in embedding-map space):\")\n",
    "                for i, (dist, (_, row)) in enumerate(zip(similar_embed_distances, similar_points.iterrows()), 1):\n",
    "                    print(f\"   {i}. '{row['Name']}' ({row['Game']}) - Map Distance: {dist:.3f}\")\n",
    "\n",
    "                # 5) Plot: all + highlight query + similar (in SAME SPACE)\n",
    "                fig = go.Figure()\n",
    "\n",
    "                # Background: all points\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=df_embed_local['embed_x'],\n",
    "                    y=df_embed_local['embed_y'],\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=3, color=KASSER_COLORS['primary'], opacity=0.15),\n",
    "                    name='All presets',\n",
    "                    hoverinfo='skip'\n",
    "                ))\n",
    "\n",
    "                # Similar points\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=similar_points['embed_x'],\n",
    "                    y=similar_points['embed_y'],\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=7, color=KASSER_COLORS['accent'], opacity=0.90,\n",
    "                                line=dict(width=1, color='white')),\n",
    "                    name='Similar (map neighbors)',\n",
    "                    text = similar_points['Name'].astype(str) + \" - \" + similar_points['Game'].astype(str),\n",
    "                    hoverinfo='text'\n",
    "                ))\n",
    "\n",
    "                # Query point on top\n",
    "                fig.add_trace(go.Scatter(\n",
    "                    x=query_point['embed_x'],\n",
    "                    y=query_point['embed_y'],\n",
    "                    mode='markers',\n",
    "                    marker=dict(size=11, color=KASSER_COLORS['secondary'], opacity=1.0,\n",
    "                                line=dict(width=2, color='white')),\n",
    "                    name='Selected preset',\n",
    "                    text = query_point['Name'].astype(str) + \" - \" + query_point['Game'].astype(str),\n",
    "                    hoverinfo='text'\n",
    "                ))\n",
    "\n",
    "                fig.update_layout(\n",
    "                    title=f\"Embedding Map ‚Äî Selected preset + {NUM_SIMILAR} nearest (in-map distance)\",\n",
    "                    plot_bgcolor=KASSER_COLORS['background'],\n",
    "                    paper_bgcolor=KASSER_COLORS['background'],\n",
    "                    font_color=KASSER_COLORS['text'],\n",
    "                    title_font_color=KASSER_COLORS['text'],\n",
    "                    font_family='sans-serif',\n",
    "                    width=1100,\n",
    "                    height=800,\n",
    "                    showlegend=True,\n",
    "                    legend=dict(\n",
    "                        bgcolor='rgba(0,0,0,0.8)',\n",
    "                        bordercolor=KASSER_COLORS['primary'],\n",
    "                        borderwidth=1\n",
    "                    )\n",
    "                )\n",
    "                fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 14. Reflection on Results\n",
    "\n",
    "### 14.1 What the Data Tells Us\n",
    "\n",
    "**Key Findings:**\n",
    "\n",
    "1. **Algorithm Distribution**: Most presets use algorithms 0-4, with algorithm 4 being particularly common\n",
    "2. **Feedback Usage**: Feedback levels vary widely, contributing to different timbral characteristics\n",
    "3. **Brightness & Complexity**: Derived features reveal distinct \"families\" of sounds\n",
    "4. **Game Signatures**: Different games show unique parameter distributions\n",
    "5. **Composer Styles**: Composers have identifiable \"sonic signatures\" in their preset choices\n",
    "6. **Regional Patterns**: Japanese and American composers show different approaches to FM synthesis\n",
    "\n",
    "**The Machine Learning Success:**\n",
    "- PCA successfully compressed 58D ‚Üí 50D with minimal information loss\n",
    "- t-SNE/UMAP created meaningful 2D visualizations\n",
    "- Clustering revealed natural groups of similar sounds\n",
    "- Similarity search enables instant preset discovery\n",
    "\n",
    "**The Creative Insights:**\n",
    "- Composers developed distinct \"sonic signatures\"\n",
    "- Games have unique \"sonic identities\"\n",
    "- Regional differences are visible in the data\n",
    "- Tool choice (GEMS vs custom) affected sound design"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 15. Challenges for Data Scientists\n",
    "\n",
    "**Kaggle-Style Challenges:**\n",
    "\n",
    "Below are challenges you can tackle to deepen your understanding of the data and machine learning. Each challenge builds on the previous one, from beginner to advanced.\n",
    "\n",
    "### 15.1 Bronze Challenge: Basic Analysis\n",
    "\n",
    "**Objective:** Understand the dataset structure and basic statistics.\n",
    "\n",
    "**Tasks:**\n",
    "1. Calculate the distribution of each algorithm (CON 0-7)\n",
    "2. Find the game with the most presets\n",
    "3. Calculate average brightness and complexity per game\n",
    "4. Visualize algorithm distribution by top 10 games\n",
    "\n",
    "**Success Metric:** Create a clear visualization showing algorithm preferences by game.\n",
    "\n",
    "**Skills Learned:** Data manipulation, basic statistics, visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.2 Silver Challenge: Advanced Clustering\n",
    "\n",
    "**Objective:** Improve clustering and interpret the results.\n",
    "\n",
    "**Tasks:**\n",
    "1. Use the Elbow Method to find optimal number of clusters\n",
    "2. Try different clustering algorithms (DBSCAN, Hierarchical)\n",
    "3. Analyze cluster characteristics (what makes each cluster unique?)\n",
    "4. Visualize clusters in the embedding space\n",
    "5. Create a \"cluster profile\" for each cluster (typical parameters, common games)\n",
    "\n",
    "**Success Metric:** Identify at least 5 distinct, interpretable clusters with clear characteristics.\n",
    "\n",
    "**Skills Learned:** Clustering algorithms, evaluation metrics, interpretation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.3 Gold Challenge: Predicting the Composer\n",
    "\n",
    "**Objective:** Build a model to predict composer from preset parameters.\n",
    "\n",
    "**Tasks:**\n",
    "1. Prepare a dataset with presets that have known composers\n",
    "2. Split into train/test sets\n",
    "3. Train a classifier (Random Forest, SVM, or Neural Network)\n",
    "4. Evaluate accuracy\n",
    "5. Analyze which parameters are most important for prediction\n",
    "6. Visualize misclassifications (what makes them hard to predict?)\n",
    "\n",
    "**Success Metric:** Achieve >60% accuracy in composer prediction.\n",
    "\n",
    "**Skills Learned:** Supervised learning, feature importance, model evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 15.4 Diamond Challenge: Presets Generation\n",
    "\n",
    "**Objective:** Generate new presets inspired by the dataset.\n",
    "\n",
    "**Tasks:**\n",
    "1. Train a generative model (VAE, GAN, or Transformer) on preset parameters\n",
    "2. Generate new presets\n",
    "3. Evaluate quality (do they sound good? are they realistic?)\n",
    "4. Create a \"preset morphing\" system (interpolate between two presets)\n",
    "5. Build a recommendation system: \"Generate a preset similar to X but with Y characteristics\"\n",
    "\n",
    "**Success Metric:** Generate at least 10 presets that sound musically useful.\n",
    "\n",
    "**Skills Learned:** Generative models, deep learning, creative AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# PART VI: EXPORT AND CONCLUSIONS\n",
    "\n",
    "## 16. Export artifacts for Web App\n",
    "\n",
    "**Why Export?**\n",
    "\n",
    "The analysis becomes truly powerful when others can interact with it. By exporting our models and processed data, we enable:\n",
    "- Interactive exploration in the web app\n",
    "- Real-time similarity search\n",
    "- Preset discovery and recommendation\n",
    "- Educational tools for learning FM synthesis\n",
    "\n",
    "**Cached Artifacts (saved during computation):**\n",
    "- `scaler.joblib` + `X_scaled.joblib`: Normalization parameters and scaled data\n",
    "- `pca_model.joblib` + `X_pca.joblib`: PCA model and transformed data\n",
    "- `embedding_2d.joblib`: t-SNE/UMAP 2D coordinates\n",
    "- `elbow_results.joblib`: Elbow method results\n",
    "- `cluster_results.joblib`: KMeans clustering results\n",
    "- `feature_columns.json`: Feature column names\n",
    "\n",
    "**Final Export (for web app):**\n",
    "- `embedding_coordinates.csv`: 2D map with metadata\n",
    "- `nn_index.joblib`: Nearest neighbors index for similarity search\n",
    "- `composer_mapping.csv`: Game-composer relationships\n",
    "- `presets_sample.csv`: Sample presets for web app\n",
    "\n",
    "**Note:** Artifacts are cached during computation - if they exist, they're loaded instead of recomputed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================================\n",
    "# FINAL EXPORT: Save remaining artifacts for web app\n",
    "# ============================================================================\n",
    "# Note: Many artifacts were already saved during computation (with caching):\n",
    "#   - scaler.joblib, X_scaled.joblib\n",
    "#   - pca_model.joblib, X_pca.joblib  \n",
    "#   - embedding_2d.joblib\n",
    "#   - elbow_results.joblib\n",
    "#   - cluster_results.joblib\n",
    "#   - feature_columns.json\n",
    "\n",
    "print('üíæ Saving final artifacts for web app...')\n",
    "\n",
    "# 1. Save embedding coordinates with all metadata (for web app visualization)\n",
    "embedding_export = df_embed[['embed_x', 'embed_y', 'Name', 'Game', 'CON', 'FL', \n",
    "                              'Brightness_Index', 'Complexity_Score']].copy()\n",
    "if 'Composer' in df_embed.columns:\n",
    "    embedding_export['Composer'] = df_embed['Composer']\n",
    "if 'Nationality' in df_embed.columns:\n",
    "    embedding_export['Nationality'] = df_embed['Nationality']\n",
    "if 'Cluster' in df_embed.columns:\n",
    "    embedding_export['Cluster'] = df_embed['Cluster']\n",
    "\n",
    "embedding_export.to_csv(ARTIFACTS_DIR / 'embedding_coordinates.csv', index=False)\n",
    "print('‚úÖ Saved: embedding_coordinates.csv')\n",
    "\n",
    "# 2. Save Nearest Neighbors index (for similarity search)\n",
    "NN_CACHE = ARTIFACTS_DIR / 'nn_index.joblib'\n",
    "if not NN_CACHE.exists():\n",
    "    joblib.dump(nn, NN_CACHE)\n",
    "    print('‚úÖ Saved: nn_index.joblib')\n",
    "else:\n",
    "    print('‚úÖ nn_index.joblib already cached')\n",
    "\n",
    "# 3. Save composer mapping (if available)\n",
    "if 'composer_df' in locals() and len(composer_df) > 0:\n",
    "    composer_df.to_csv(ARTIFACTS_DIR / 'composer_mapping.csv', index=False)\n",
    "    print('‚úÖ Saved: composer_mapping.csv')\n",
    "\n",
    "# 4. Save full enriched dataset (sample for web app - smaller file)\n",
    "if 'df_enriched' in locals():\n",
    "    df_enriched_sample = df_enriched.sample(min(10000, len(df_enriched)), random_state=42)\n",
    "    df_enriched_sample.to_csv(ARTIFACTS_DIR / 'presets_sample.csv', index=False)\n",
    "    print('‚úÖ Saved: presets_sample.csv')\n",
    "\n",
    "# List all cached artifacts\n",
    "print(f'\\nüìÅ All artifacts in {ARTIFACTS_DIR}/')\n",
    "for f in sorted(ARTIFACTS_DIR.glob('*')):\n",
    "    size_mb = f.stat().st_size / (1024 * 1024)\n",
    "    print(f'   {f.name}: {size_mb:.2f} MB')\n",
    "\n",
    "print(f'\\nüéâ Export complete!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 17. Conclusions and Creative Inspiration\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "1. **Algorithm Distribution**: Most presets use algorithms 0-4, with algorithm 4 being particularly common\n",
    "2. **Feedback Usage**: Feedback levels vary widely, contributing to different timbral characteristics\n",
    "3. **Brightness & Complexity**: Derived features reveal distinct \"families\" of sounds\n",
    "4. **Game Signatures**: Different games show unique parameter distributions\n",
    "5. **Composer Styles**: Composers have identifiable \"sonic signatures\" in their preset choices\n",
    "6. **Regional Patterns**: Japanese and American composers show different approaches to FM synthesis\n",
    "\n",
    "### How to Use This Analysis\n",
    "\n",
    "- **For Musicians**: Use the similarity system to find presets that match your desired sound\n",
    "- **For Sound Designers**: Study the parameter combinations that create specific timbres\n",
    "- **For Composers**: Explore how legendary composers used FM synthesis to create iconic sounds\n",
    "- **For Researchers**: The dataset and analysis provide insights into the evolution of game music\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "1. **Explore the Web App**: Interactive visualization and preset exploration\n",
    "2. **Download Presets**: Export presets in DMP format for use in DefleMask\n",
    "3. **Create Your Own**: Use the insights to design new presets inspired by the classics\n",
    "\n",
    "### Resources\n",
    "\n",
    "- **Kasser Synths**: [kassersynths.com](https://kassersynths.com)\n",
    "- **DefleMask**: [deflemask.com](https://deflemask.com)\n",
    "- **VGMdb**: [vgmdb.net](https://vgmdb.net)\n",
    "\n",
    "---\n",
    "\n",
    "**Thank you for exploring the sonic DNA of the Sega Genesis era!** üéµüéÆ\n",
    "\n",
    "<div align=\"center\" style=\"margin-top: 40px; padding: 20px; border-top: 2px solid #00d4ff;\">\n",
    "\n",
    "### <span style=\"color: #00d4ff\">KASSER</span> <span style=\"color: #ffffff\">SYNTHS</span>\n",
    "\n",
    "*This analysis was created with ‚ù§Ô∏è for the retro gaming and chiptune community.*\n",
    "\n",
    "**Visit us at [kassersynths.com](https://kassersynths.com)**\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
